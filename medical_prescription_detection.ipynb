{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnB-Jwux_IHl"
      },
      "source": [
        "#Load Data From Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1xIHG2uYnyI",
        "outputId": "36a00324-d9ee-4850-d023-d01d46359476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/New_Dataset.zip\", 'r')\n",
        "# zip_ref.extractall(\"/content\")\n",
        "# zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtm3BKVGUEKO"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqLYVNaYThRs"
      },
      "outputs": [],
      "source": [
        "%pip install -q pyunpack\n",
        "from pyunpack import Archive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import glob as gb\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras import models, regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, Activation, MaxPooling2D\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Input, BatchNormalization, Dropout, ZeroPadding2D\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score\n",
        "sns.set(rc={'figure.figsize':(15,10)})\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from natsort import natsorted\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIppQebyTj7T"
      },
      "outputs": [],
      "source": [
        "# name of each unique drugs\n",
        "classes = ['cataflam', 'ketolac', 'brufen', 'panadol', 'Actos'] #, 'Diclac', 'Insulin'\n",
        "# size of image\n",
        "img_size = 224"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SVyu8LiUYB0"
      },
      "source": [
        "# from path get images as numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RHimqft2Tex2"
      },
      "outputs": [],
      "source": [
        "def get_images(path):\n",
        "  data = []\n",
        "  for label in classes:\n",
        "    # get all images in this file\n",
        "    print(path+label)\n",
        "    images = gb.glob(pathname=str(path + label + '/*.jpg'))\n",
        "    # get the index\n",
        "    class_num = classes.index(label)\n",
        "    # loop in all images\n",
        "    for image in images:\n",
        "      image_array = cv2.imread(os.path.join(path, image), cv2.IMREAD_COLOR)\n",
        "      # get the width and height of image\n",
        "      width, height = Image.open(image).size\n",
        "      # resize images\n",
        "      resized_img = cv2.resize(image_array, (img_size, img_size))\n",
        "      data.append([resized_img, class_num])\n",
        "  return np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AoIH-akSseE",
        "outputId": "1f20f7b8-3e84-4f5e-9a0a-ab3ce86c1738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/hema/cataflam\n",
            "/content/drive/MyDrive/hema/ketolac\n",
            "/content/drive/MyDrive/hema/brufen\n",
            "/content/drive/MyDrive/hema/panadol\n",
            "/content/drive/MyDrive/hema/Actos\n",
            "/content/drive/MyDrive/test/cataflam\n",
            "/content/drive/MyDrive/test/ketolac\n",
            "/content/drive/MyDrive/test/brufen\n",
            "/content/drive/MyDrive/test/panadol\n",
            "/content/drive/MyDrive/test/Actos\n"
          ]
        }
      ],
      "source": [
        "train = get_images(r'/content/drive/MyDrive/hema/')\n",
        "test = get_images(r'/content/drive/MyDrive/test/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fck6UKHmUigT"
      },
      "source": [
        "# make data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gAfu0JpWAbg"
      },
      "outputs": [],
      "source": [
        "def get_x_y(data):\n",
        "  x, y = [], []\n",
        "  for feature, label in data:\n",
        "    x.append(feature)\n",
        "    y.append(label)\n",
        "  print(len(x))\n",
        "  print(len(y))\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbRPLl7seUjn",
        "outputId": "089e5519-a04b-412a-cea2-65336d9ca1bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1809\n",
            "1809\n",
            "223\n",
            "223\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = get_x_y(train)\n",
        "x_test, y_test = get_x_y(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ7uoSwGUoOL"
      },
      "source": [
        "# Scale x and convert x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqqvfD5cWREY"
      },
      "outputs": [],
      "source": [
        "x_train = np.array(x_train) / 255\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp-bolxUeUjp"
      },
      "outputs": [],
      "source": [
        "x_test = np.array(x_test) / 255\n",
        "y_test = np.array(y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-drzXa_gUszO"
      },
      "source": [
        "# reshape x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37l33cJLWmtR",
        "outputId": "25c3e8bd-e75c-43c0-990a-d34d8753033a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1809, 224, 224, 3)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# x_train = x_train.reshape(1043,224,224,3)\n",
        "x_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNzp-3l6eUjq",
        "outputId": "964bda11-ed6a-487b-a290-9e2844d8f462"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(223, 224, 224, 3)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# x_test = x_test.reshape(97, 224, 224, 3)\n",
        "x_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUvdyEX4Uxkn"
      },
      "source": [
        "# make dummies for y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXc78ujZWpzd"
      },
      "outputs": [],
      "source": [
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbP7oof9U76G"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzoUlewAbiVm",
        "outputId": "d6d013e3-7eb0-469c-f9b1-3664b08fa4cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 17s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#Load PreTrained Model\n",
        "vgg16_model = tf.keras.applications.vgg16.VGG16()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWoiaVi8buto",
        "outputId": "894bb41a-0510-4512-ac82-8634524de41e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vgg16_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU-cJn1UcAz3"
      },
      "outputs": [],
      "source": [
        "#Build New Model By PreTrained Model Layer Without Last Layer\n",
        "model=keras.Sequential()\n",
        "for layer in vgg16_model.layers[:-1]:\n",
        "  model.add(layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2uPNDgXcCUL"
      },
      "outputs": [],
      "source": [
        "#Freeze Layer Of PreTrained Model From Train\n",
        "for layer in model.layers:\n",
        "  layer.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lj52Ygn8prq"
      },
      "outputs": [],
      "source": [
        "#Add new Layer to Model\n",
        "model.add(keras.layers.Dense(5, activation='Softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GISD-DH1cU-G",
        "outputId": "14af99be-6c75-41fa-d977-591b180a32a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 28679     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,289,223\n",
            "Trainable params: 28,679\n",
            "Non-trainable params: 134,260,544\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrgf4QzvXB4E"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RSiVgVq4osG"
      },
      "outputs": [],
      "source": [
        "# callback = [tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_accuracy'),\n",
        "#             tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', patience = 2, factor=0.25, verbose=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCV8wer4XB1Z",
        "outputId": "11b0820e-25ed-4586-ac45-e70bdb306d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "243/243 [==============================] - 28s 69ms/step - loss: 1.9916 - accuracy: 0.2418 - val_loss: 2.3638 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/500\n",
            "243/243 [==============================] - 15s 60ms/step - loss: 1.6328 - accuracy: 0.3937 - val_loss: 1.3688 - val_accuracy: 0.3359\n",
            "Epoch 3/500\n",
            "243/243 [==============================] - 15s 61ms/step - loss: 1.3563 - accuracy: 0.5045 - val_loss: 2.4626 - val_accuracy: 0.0781\n",
            "Epoch 4/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 1.1967 - accuracy: 0.5848 - val_loss: 1.1057 - val_accuracy: 0.7891\n",
            "Epoch 5/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 1.1260 - accuracy: 0.6120 - val_loss: 2.7708 - val_accuracy: 0.2266\n",
            "Epoch 6/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 1.0389 - accuracy: 0.6371 - val_loss: 1.6399 - val_accuracy: 0.2109\n",
            "Epoch 7/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.9745 - accuracy: 0.6717 - val_loss: 1.8152 - val_accuracy: 0.2109\n",
            "Epoch 8/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.8825 - accuracy: 0.7010 - val_loss: 2.8359 - val_accuracy: 0.0547\n",
            "Epoch 9/500\n",
            "243/243 [==============================] - 15s 63ms/step - loss: 0.8537 - accuracy: 0.7179 - val_loss: 1.9833 - val_accuracy: 0.2031\n",
            "Epoch 10/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.8021 - accuracy: 0.7319 - val_loss: 1.5305 - val_accuracy: 0.2578\n",
            "Epoch 11/500\n",
            "243/243 [==============================] - 15s 63ms/step - loss: 0.7673 - accuracy: 0.7484 - val_loss: 3.1152 - val_accuracy: 0.0625\n",
            "Epoch 12/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.7508 - accuracy: 0.7451 - val_loss: 1.6395 - val_accuracy: 0.3984\n",
            "Epoch 13/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.6822 - accuracy: 0.7772 - val_loss: 2.0853 - val_accuracy: 0.1562\n",
            "Epoch 14/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.6656 - accuracy: 0.7801 - val_loss: 1.1498 - val_accuracy: 0.6016\n",
            "Epoch 15/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.6215 - accuracy: 0.8015 - val_loss: 1.8476 - val_accuracy: 0.1406\n",
            "Epoch 16/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.5890 - accuracy: 0.8192 - val_loss: 1.6063 - val_accuracy: 0.3281\n",
            "Epoch 17/500\n",
            "243/243 [==============================] - 15s 63ms/step - loss: 0.5554 - accuracy: 0.8311 - val_loss: 0.8682 - val_accuracy: 0.6484\n",
            "Epoch 18/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.5899 - accuracy: 0.8072 - val_loss: 2.2522 - val_accuracy: 0.2734\n",
            "Epoch 19/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.5133 - accuracy: 0.8493 - val_loss: 1.7721 - val_accuracy: 0.3125\n",
            "Epoch 20/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.5422 - accuracy: 0.8402 - val_loss: 1.7301 - val_accuracy: 0.3594\n",
            "Epoch 21/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.5240 - accuracy: 0.8353 - val_loss: 1.6842 - val_accuracy: 0.3281\n",
            "Epoch 22/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.4513 - accuracy: 0.8682 - val_loss: 1.5993 - val_accuracy: 0.4297\n",
            "Epoch 23/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.4782 - accuracy: 0.8451 - val_loss: 1.4254 - val_accuracy: 0.4375\n",
            "Epoch 24/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.4264 - accuracy: 0.8851 - val_loss: 1.6458 - val_accuracy: 0.4375\n",
            "Epoch 25/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.4240 - accuracy: 0.8818 - val_loss: 1.6116 - val_accuracy: 0.3438\n",
            "Epoch 26/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.4096 - accuracy: 0.8900 - val_loss: 0.9875 - val_accuracy: 0.6250\n",
            "Epoch 27/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.4558 - accuracy: 0.8563 - val_loss: 1.5903 - val_accuracy: 0.3984\n",
            "Epoch 28/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.4287 - accuracy: 0.8703 - val_loss: 1.4680 - val_accuracy: 0.3359\n",
            "Epoch 29/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.3923 - accuracy: 0.8810 - val_loss: 1.7829 - val_accuracy: 0.3125\n",
            "Epoch 30/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.3847 - accuracy: 0.8946 - val_loss: 1.3631 - val_accuracy: 0.4766\n",
            "Epoch 31/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.3735 - accuracy: 0.8974 - val_loss: 1.8456 - val_accuracy: 0.3438\n",
            "Epoch 32/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.3791 - accuracy: 0.8834 - val_loss: 1.4459 - val_accuracy: 0.5625\n",
            "Epoch 33/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.3424 - accuracy: 0.9065 - val_loss: 1.5458 - val_accuracy: 0.3125\n",
            "Epoch 34/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.3526 - accuracy: 0.8909 - val_loss: 1.2147 - val_accuracy: 0.5312\n",
            "Epoch 35/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.3479 - accuracy: 0.8987 - val_loss: 1.3210 - val_accuracy: 0.5469\n",
            "Epoch 36/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.3554 - accuracy: 0.8876 - val_loss: 0.9346 - val_accuracy: 0.6484\n",
            "Epoch 37/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.3251 - accuracy: 0.9061 - val_loss: 1.9885 - val_accuracy: 0.3438\n",
            "Epoch 38/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.3223 - accuracy: 0.9069 - val_loss: 1.1407 - val_accuracy: 0.5469\n",
            "Epoch 39/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.3444 - accuracy: 0.8921 - val_loss: 1.1315 - val_accuracy: 0.5391\n",
            "Epoch 40/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.2901 - accuracy: 0.9201 - val_loss: 1.0957 - val_accuracy: 0.5312\n",
            "Epoch 41/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.2954 - accuracy: 0.9143 - val_loss: 2.2592 - val_accuracy: 0.2422\n",
            "Epoch 42/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.2894 - accuracy: 0.9180 - val_loss: 1.3307 - val_accuracy: 0.4531\n",
            "Epoch 43/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.2774 - accuracy: 0.9226 - val_loss: 1.3981 - val_accuracy: 0.4766\n",
            "Epoch 44/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.2730 - accuracy: 0.9287 - val_loss: 1.1157 - val_accuracy: 0.5703\n",
            "Epoch 45/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.2789 - accuracy: 0.9152 - val_loss: 1.7797 - val_accuracy: 0.4531\n",
            "Epoch 46/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.2664 - accuracy: 0.9242 - val_loss: 1.3981 - val_accuracy: 0.4922\n",
            "Epoch 47/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.3008 - accuracy: 0.9094 - val_loss: 1.7372 - val_accuracy: 0.4141\n",
            "Epoch 48/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.2491 - accuracy: 0.9267 - val_loss: 1.4103 - val_accuracy: 0.4453\n",
            "Epoch 49/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.2490 - accuracy: 0.9353 - val_loss: 2.1993 - val_accuracy: 0.4609\n",
            "Epoch 50/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.2498 - accuracy: 0.9275 - val_loss: 1.3698 - val_accuracy: 0.4766\n",
            "Epoch 51/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.2264 - accuracy: 0.9407 - val_loss: 1.4153 - val_accuracy: 0.4453\n",
            "Epoch 52/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.2424 - accuracy: 0.9287 - val_loss: 0.9143 - val_accuracy: 0.6406\n",
            "Epoch 53/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.2422 - accuracy: 0.9333 - val_loss: 1.2563 - val_accuracy: 0.4922\n",
            "Epoch 54/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.2738 - accuracy: 0.9193 - val_loss: 1.9579 - val_accuracy: 0.3125\n",
            "Epoch 55/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.2285 - accuracy: 0.9362 - val_loss: 1.4485 - val_accuracy: 0.4375\n",
            "Epoch 56/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.2374 - accuracy: 0.9312 - val_loss: 1.7155 - val_accuracy: 0.3828\n",
            "Epoch 57/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.2249 - accuracy: 0.9316 - val_loss: 1.6831 - val_accuracy: 0.4688\n",
            "Epoch 58/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.2265 - accuracy: 0.9325 - val_loss: 1.4962 - val_accuracy: 0.4219\n",
            "Epoch 59/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.2223 - accuracy: 0.9378 - val_loss: 1.5542 - val_accuracy: 0.3828\n",
            "Epoch 60/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.2110 - accuracy: 0.9407 - val_loss: 0.7244 - val_accuracy: 0.7031\n",
            "Epoch 61/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.2258 - accuracy: 0.9329 - val_loss: 2.6695 - val_accuracy: 0.2266\n",
            "Epoch 62/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.2248 - accuracy: 0.9296 - val_loss: 1.2683 - val_accuracy: 0.5312\n",
            "Epoch 63/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.2252 - accuracy: 0.9325 - val_loss: 0.6365 - val_accuracy: 0.7891\n",
            "Epoch 64/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.2028 - accuracy: 0.9382 - val_loss: 2.2692 - val_accuracy: 0.2656\n",
            "Epoch 65/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1870 - accuracy: 0.9518 - val_loss: 1.1076 - val_accuracy: 0.5781\n",
            "Epoch 66/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.2252 - accuracy: 0.9296 - val_loss: 0.5383 - val_accuracy: 0.8359\n",
            "Epoch 67/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1907 - accuracy: 0.9423 - val_loss: 0.6982 - val_accuracy: 0.7109\n",
            "Epoch 68/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1740 - accuracy: 0.9547 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
            "Epoch 69/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1658 - accuracy: 0.9596 - val_loss: 0.5012 - val_accuracy: 0.8516\n",
            "Epoch 70/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1840 - accuracy: 0.9481 - val_loss: 1.6457 - val_accuracy: 0.4453\n",
            "Epoch 71/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.2324 - accuracy: 0.9308 - val_loss: 2.1055 - val_accuracy: 0.2656\n",
            "Epoch 72/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1863 - accuracy: 0.9456 - val_loss: 1.8513 - val_accuracy: 0.4297\n",
            "Epoch 73/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1716 - accuracy: 0.9522 - val_loss: 0.9106 - val_accuracy: 0.6250\n",
            "Epoch 74/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1991 - accuracy: 0.9374 - val_loss: 1.5205 - val_accuracy: 0.4297\n",
            "Epoch 75/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1862 - accuracy: 0.9428 - val_loss: 1.0613 - val_accuracy: 0.6250\n",
            "Epoch 76/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1997 - accuracy: 0.9357 - val_loss: 1.2839 - val_accuracy: 0.5234\n",
            "Epoch 77/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1853 - accuracy: 0.9423 - val_loss: 1.2958 - val_accuracy: 0.5391\n",
            "Epoch 78/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1799 - accuracy: 0.9473 - val_loss: 1.5299 - val_accuracy: 0.4375\n",
            "Epoch 79/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1699 - accuracy: 0.9493 - val_loss: 1.2232 - val_accuracy: 0.4922\n",
            "Epoch 80/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1775 - accuracy: 0.9518 - val_loss: 0.9718 - val_accuracy: 0.6172\n",
            "Epoch 81/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1663 - accuracy: 0.9522 - val_loss: 1.1107 - val_accuracy: 0.5703\n",
            "Epoch 82/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1560 - accuracy: 0.9559 - val_loss: 1.3166 - val_accuracy: 0.4844\n",
            "Epoch 83/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.2149 - accuracy: 0.9337 - val_loss: 1.7071 - val_accuracy: 0.3438\n",
            "Epoch 84/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1786 - accuracy: 0.9444 - val_loss: 0.7594 - val_accuracy: 0.6953\n",
            "Epoch 85/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1717 - accuracy: 0.9522 - val_loss: 1.5541 - val_accuracy: 0.4609\n",
            "Epoch 86/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1827 - accuracy: 0.9444 - val_loss: 1.3959 - val_accuracy: 0.5234\n",
            "Epoch 87/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1599 - accuracy: 0.9526 - val_loss: 0.7795 - val_accuracy: 0.6797\n",
            "Epoch 88/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1792 - accuracy: 0.9465 - val_loss: 0.7356 - val_accuracy: 0.7031\n",
            "Epoch 89/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1718 - accuracy: 0.9522 - val_loss: 0.4451 - val_accuracy: 0.8516\n",
            "Epoch 90/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1605 - accuracy: 0.9518 - val_loss: 1.9580 - val_accuracy: 0.4297\n",
            "Epoch 91/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1604 - accuracy: 0.9518 - val_loss: 1.2610 - val_accuracy: 0.5156\n",
            "Epoch 92/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1471 - accuracy: 0.9572 - val_loss: 1.1387 - val_accuracy: 0.5703\n",
            "Epoch 93/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1499 - accuracy: 0.9535 - val_loss: 0.8399 - val_accuracy: 0.7344\n",
            "Epoch 94/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1359 - accuracy: 0.9629 - val_loss: 1.3565 - val_accuracy: 0.4844\n",
            "Epoch 95/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1420 - accuracy: 0.9621 - val_loss: 1.6190 - val_accuracy: 0.5234\n",
            "Epoch 96/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1726 - accuracy: 0.9506 - val_loss: 1.5274 - val_accuracy: 0.4688\n",
            "Epoch 97/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1346 - accuracy: 0.9695 - val_loss: 2.0159 - val_accuracy: 0.4375\n",
            "Epoch 98/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1568 - accuracy: 0.9502 - val_loss: 0.9934 - val_accuracy: 0.6016\n",
            "Epoch 99/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1251 - accuracy: 0.9650 - val_loss: 2.5228 - val_accuracy: 0.3984\n",
            "Epoch 100/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1405 - accuracy: 0.9613 - val_loss: 0.7395 - val_accuracy: 0.7734\n",
            "Epoch 101/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1969 - accuracy: 0.9337 - val_loss: 0.4058 - val_accuracy: 0.8750\n",
            "Epoch 102/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1548 - accuracy: 0.9576 - val_loss: 1.5320 - val_accuracy: 0.4844\n",
            "Epoch 103/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1495 - accuracy: 0.9559 - val_loss: 1.6591 - val_accuracy: 0.5078\n",
            "Epoch 104/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1189 - accuracy: 0.9687 - val_loss: 1.1532 - val_accuracy: 0.5703\n",
            "Epoch 105/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1286 - accuracy: 0.9650 - val_loss: 1.9245 - val_accuracy: 0.4531\n",
            "Epoch 106/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1360 - accuracy: 0.9600 - val_loss: 0.9898 - val_accuracy: 0.6953\n",
            "Epoch 107/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1267 - accuracy: 0.9621 - val_loss: 0.9980 - val_accuracy: 0.5938\n",
            "Epoch 108/500\n",
            "243/243 [==============================] - 15s 63ms/step - loss: 0.1453 - accuracy: 0.9559 - val_loss: 2.3754 - val_accuracy: 0.5312\n",
            "Epoch 109/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.1343 - accuracy: 0.9650 - val_loss: 1.1348 - val_accuracy: 0.5859\n",
            "Epoch 110/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1186 - accuracy: 0.9658 - val_loss: 1.6503 - val_accuracy: 0.4531\n",
            "Epoch 111/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1571 - accuracy: 0.9506 - val_loss: 1.4373 - val_accuracy: 0.5000\n",
            "Epoch 112/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1719 - accuracy: 0.9390 - val_loss: 0.8962 - val_accuracy: 0.6641\n",
            "Epoch 113/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.1035 - accuracy: 0.9745 - val_loss: 1.4042 - val_accuracy: 0.5000\n",
            "Epoch 114/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1304 - accuracy: 0.9621 - val_loss: 1.2580 - val_accuracy: 0.5391\n",
            "Epoch 115/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1653 - accuracy: 0.9444 - val_loss: 1.2963 - val_accuracy: 0.5312\n",
            "Epoch 116/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1468 - accuracy: 0.9547 - val_loss: 0.7418 - val_accuracy: 0.7344\n",
            "Epoch 117/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1290 - accuracy: 0.9666 - val_loss: 0.6794 - val_accuracy: 0.7109\n",
            "Epoch 118/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1415 - accuracy: 0.9568 - val_loss: 1.2005 - val_accuracy: 0.5781\n",
            "Epoch 119/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1111 - accuracy: 0.9675 - val_loss: 0.9752 - val_accuracy: 0.6484\n",
            "Epoch 120/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1178 - accuracy: 0.9691 - val_loss: 1.5354 - val_accuracy: 0.4922\n",
            "Epoch 121/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1246 - accuracy: 0.9605 - val_loss: 0.6735 - val_accuracy: 0.7500\n",
            "Epoch 122/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1359 - accuracy: 0.9580 - val_loss: 1.1591 - val_accuracy: 0.6016\n",
            "Epoch 123/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0985 - accuracy: 0.9757 - val_loss: 1.0890 - val_accuracy: 0.6094\n",
            "Epoch 124/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1154 - accuracy: 0.9650 - val_loss: 2.0857 - val_accuracy: 0.3906\n",
            "Epoch 125/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1352 - accuracy: 0.9596 - val_loss: 0.7130 - val_accuracy: 0.6953\n",
            "Epoch 126/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0982 - accuracy: 0.9732 - val_loss: 0.8598 - val_accuracy: 0.7109\n",
            "Epoch 127/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1093 - accuracy: 0.9691 - val_loss: 1.3650 - val_accuracy: 0.5312\n",
            "Epoch 128/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1121 - accuracy: 0.9662 - val_loss: 1.6244 - val_accuracy: 0.5781\n",
            "Epoch 129/500\n",
            "243/243 [==============================] - 16s 65ms/step - loss: 0.1034 - accuracy: 0.9724 - val_loss: 0.9383 - val_accuracy: 0.6406\n",
            "Epoch 130/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1044 - accuracy: 0.9683 - val_loss: 2.7050 - val_accuracy: 0.2266\n",
            "Epoch 131/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1177 - accuracy: 0.9633 - val_loss: 0.7443 - val_accuracy: 0.7578\n",
            "Epoch 132/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1041 - accuracy: 0.9720 - val_loss: 1.1223 - val_accuracy: 0.5938\n",
            "Epoch 133/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1037 - accuracy: 0.9703 - val_loss: 1.0195 - val_accuracy: 0.6875\n",
            "Epoch 134/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1138 - accuracy: 0.9617 - val_loss: 1.5297 - val_accuracy: 0.4922\n",
            "Epoch 135/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1093 - accuracy: 0.9654 - val_loss: 0.8539 - val_accuracy: 0.6953\n",
            "Epoch 136/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0920 - accuracy: 0.9753 - val_loss: 1.3189 - val_accuracy: 0.5625\n",
            "Epoch 137/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0958 - accuracy: 0.9765 - val_loss: 0.8614 - val_accuracy: 0.6484\n",
            "Epoch 138/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1074 - accuracy: 0.9654 - val_loss: 1.2018 - val_accuracy: 0.5938\n",
            "Epoch 139/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1186 - accuracy: 0.9679 - val_loss: 0.7792 - val_accuracy: 0.7031\n",
            "Epoch 140/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1344 - accuracy: 0.9559 - val_loss: 1.0051 - val_accuracy: 0.6172\n",
            "Epoch 141/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0996 - accuracy: 0.9699 - val_loss: 1.5764 - val_accuracy: 0.4766\n",
            "Epoch 142/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1082 - accuracy: 0.9662 - val_loss: 1.0319 - val_accuracy: 0.6641\n",
            "Epoch 143/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0910 - accuracy: 0.9736 - val_loss: 0.8292 - val_accuracy: 0.7031\n",
            "Epoch 144/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1155 - accuracy: 0.9650 - val_loss: 1.2416 - val_accuracy: 0.5625\n",
            "Epoch 145/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0956 - accuracy: 0.9736 - val_loss: 1.7295 - val_accuracy: 0.4766\n",
            "Epoch 146/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1019 - accuracy: 0.9720 - val_loss: 1.0249 - val_accuracy: 0.6250\n",
            "Epoch 147/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0821 - accuracy: 0.9811 - val_loss: 0.7522 - val_accuracy: 0.7266\n",
            "Epoch 148/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0866 - accuracy: 0.9753 - val_loss: 1.4883 - val_accuracy: 0.5312\n",
            "Epoch 149/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0889 - accuracy: 0.9761 - val_loss: 1.6074 - val_accuracy: 0.4609\n",
            "Epoch 150/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1608 - accuracy: 0.9485 - val_loss: 1.1165 - val_accuracy: 0.5938\n",
            "Epoch 151/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1111 - accuracy: 0.9671 - val_loss: 1.0322 - val_accuracy: 0.6172\n",
            "Epoch 152/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0993 - accuracy: 0.9720 - val_loss: 0.9808 - val_accuracy: 0.6328\n",
            "Epoch 153/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0816 - accuracy: 0.9782 - val_loss: 0.7588 - val_accuracy: 0.7812\n",
            "Epoch 154/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0964 - accuracy: 0.9724 - val_loss: 1.0224 - val_accuracy: 0.6562\n",
            "Epoch 155/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0771 - accuracy: 0.9819 - val_loss: 0.4229 - val_accuracy: 0.8516\n",
            "Epoch 156/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1004 - accuracy: 0.9699 - val_loss: 1.4572 - val_accuracy: 0.5000\n",
            "Epoch 157/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1050 - accuracy: 0.9687 - val_loss: 2.0661 - val_accuracy: 0.5000\n",
            "Epoch 158/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1096 - accuracy: 0.9621 - val_loss: 0.9617 - val_accuracy: 0.7344\n",
            "Epoch 159/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0887 - accuracy: 0.9757 - val_loss: 1.8456 - val_accuracy: 0.4375\n",
            "Epoch 160/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1213 - accuracy: 0.9588 - val_loss: 1.0090 - val_accuracy: 0.6094\n",
            "Epoch 161/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0818 - accuracy: 0.9802 - val_loss: 0.5283 - val_accuracy: 0.7969\n",
            "Epoch 162/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0863 - accuracy: 0.9773 - val_loss: 1.5319 - val_accuracy: 0.5234\n",
            "Epoch 163/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0931 - accuracy: 0.9732 - val_loss: 0.7761 - val_accuracy: 0.7656\n",
            "Epoch 164/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0822 - accuracy: 0.9778 - val_loss: 1.1275 - val_accuracy: 0.5859\n",
            "Epoch 165/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0784 - accuracy: 0.9790 - val_loss: 2.7778 - val_accuracy: 0.1953\n",
            "Epoch 166/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0810 - accuracy: 0.9765 - val_loss: 1.2603 - val_accuracy: 0.5938\n",
            "Epoch 167/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0925 - accuracy: 0.9695 - val_loss: 0.6722 - val_accuracy: 0.8125\n",
            "Epoch 168/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0946 - accuracy: 0.9728 - val_loss: 0.9868 - val_accuracy: 0.6719\n",
            "Epoch 169/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0874 - accuracy: 0.9778 - val_loss: 1.3987 - val_accuracy: 0.5312\n",
            "Epoch 170/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1236 - accuracy: 0.9592 - val_loss: 1.6037 - val_accuracy: 0.5547\n",
            "Epoch 171/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0912 - accuracy: 0.9757 - val_loss: 1.1299 - val_accuracy: 0.6328\n",
            "Epoch 172/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0811 - accuracy: 0.9786 - val_loss: 1.1044 - val_accuracy: 0.6562\n",
            "Epoch 173/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.1073 - accuracy: 0.9658 - val_loss: 0.7779 - val_accuracy: 0.7656\n",
            "Epoch 174/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1058 - accuracy: 0.9666 - val_loss: 0.8287 - val_accuracy: 0.7500\n",
            "Epoch 175/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0738 - accuracy: 0.9815 - val_loss: 1.0933 - val_accuracy: 0.6250\n",
            "Epoch 176/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0845 - accuracy: 0.9745 - val_loss: 1.6299 - val_accuracy: 0.4453\n",
            "Epoch 177/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0893 - accuracy: 0.9741 - val_loss: 1.0156 - val_accuracy: 0.6641\n",
            "Epoch 178/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1054 - accuracy: 0.9703 - val_loss: 0.5113 - val_accuracy: 0.8438\n",
            "Epoch 179/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0812 - accuracy: 0.9745 - val_loss: 0.6381 - val_accuracy: 0.7891\n",
            "Epoch 180/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0742 - accuracy: 0.9790 - val_loss: 1.7577 - val_accuracy: 0.4375\n",
            "Epoch 181/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0726 - accuracy: 0.9794 - val_loss: 0.9001 - val_accuracy: 0.7266\n",
            "Epoch 182/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0903 - accuracy: 0.9732 - val_loss: 1.1407 - val_accuracy: 0.6250\n",
            "Epoch 183/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0683 - accuracy: 0.9815 - val_loss: 1.2388 - val_accuracy: 0.5859\n",
            "Epoch 184/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0970 - accuracy: 0.9691 - val_loss: 1.0942 - val_accuracy: 0.6172\n",
            "Epoch 185/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0580 - accuracy: 0.9864 - val_loss: 0.6165 - val_accuracy: 0.8203\n",
            "Epoch 186/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0816 - accuracy: 0.9761 - val_loss: 1.3117 - val_accuracy: 0.6094\n",
            "Epoch 187/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0891 - accuracy: 0.9724 - val_loss: 0.8523 - val_accuracy: 0.7656\n",
            "Epoch 188/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0872 - accuracy: 0.9749 - val_loss: 2.3027 - val_accuracy: 0.4297\n",
            "Epoch 189/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0709 - accuracy: 0.9778 - val_loss: 0.8153 - val_accuracy: 0.6875\n",
            "Epoch 190/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0648 - accuracy: 0.9856 - val_loss: 0.6904 - val_accuracy: 0.8047\n",
            "Epoch 191/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1036 - accuracy: 0.9658 - val_loss: 0.8551 - val_accuracy: 0.7734\n",
            "Epoch 192/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0880 - accuracy: 0.9716 - val_loss: 0.9017 - val_accuracy: 0.7031\n",
            "Epoch 193/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0593 - accuracy: 0.9843 - val_loss: 1.7371 - val_accuracy: 0.4609\n",
            "Epoch 194/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0820 - accuracy: 0.9761 - val_loss: 1.3381 - val_accuracy: 0.5547\n",
            "Epoch 195/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0786 - accuracy: 0.9765 - val_loss: 0.5429 - val_accuracy: 0.8438\n",
            "Epoch 196/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0780 - accuracy: 0.9757 - val_loss: 0.7403 - val_accuracy: 0.7578\n",
            "Epoch 197/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0733 - accuracy: 0.9806 - val_loss: 0.9145 - val_accuracy: 0.6797\n",
            "Epoch 198/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0884 - accuracy: 0.9724 - val_loss: 0.9930 - val_accuracy: 0.6641\n",
            "Epoch 199/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0833 - accuracy: 0.9728 - val_loss: 1.8884 - val_accuracy: 0.4609\n",
            "Epoch 200/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0632 - accuracy: 0.9831 - val_loss: 1.6052 - val_accuracy: 0.4922\n",
            "Epoch 201/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0722 - accuracy: 0.9794 - val_loss: 1.3017 - val_accuracy: 0.5781\n",
            "Epoch 202/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1282 - accuracy: 0.9568 - val_loss: 0.6790 - val_accuracy: 0.7891\n",
            "Epoch 203/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0853 - accuracy: 0.9736 - val_loss: 0.7905 - val_accuracy: 0.7969\n",
            "Epoch 204/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0625 - accuracy: 0.9831 - val_loss: 0.2515 - val_accuracy: 0.9062\n",
            "Epoch 205/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0754 - accuracy: 0.9782 - val_loss: 0.7597 - val_accuracy: 0.7266\n",
            "Epoch 206/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0699 - accuracy: 0.9806 - val_loss: 0.2845 - val_accuracy: 0.9219\n",
            "Epoch 207/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1259 - accuracy: 0.9588 - val_loss: 1.2366 - val_accuracy: 0.5938\n",
            "Epoch 208/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0768 - accuracy: 0.9806 - val_loss: 1.4938 - val_accuracy: 0.6094\n",
            "Epoch 209/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0634 - accuracy: 0.9815 - val_loss: 0.9345 - val_accuracy: 0.6562\n",
            "Epoch 210/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0979 - accuracy: 0.9736 - val_loss: 0.6148 - val_accuracy: 0.7578\n",
            "Epoch 211/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0581 - accuracy: 0.9872 - val_loss: 1.4185 - val_accuracy: 0.5625\n",
            "Epoch 212/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0659 - accuracy: 0.9806 - val_loss: 0.5160 - val_accuracy: 0.8281\n",
            "Epoch 213/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0657 - accuracy: 0.9819 - val_loss: 1.6011 - val_accuracy: 0.4844\n",
            "Epoch 214/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0704 - accuracy: 0.9778 - val_loss: 1.9310 - val_accuracy: 0.4609\n",
            "Epoch 215/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0833 - accuracy: 0.9782 - val_loss: 0.9818 - val_accuracy: 0.7188\n",
            "Epoch 216/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0545 - accuracy: 0.9885 - val_loss: 1.3972 - val_accuracy: 0.5469\n",
            "Epoch 217/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0715 - accuracy: 0.9769 - val_loss: 1.5846 - val_accuracy: 0.4922\n",
            "Epoch 218/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0667 - accuracy: 0.9815 - val_loss: 0.8265 - val_accuracy: 0.7109\n",
            "Epoch 219/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0712 - accuracy: 0.9802 - val_loss: 1.0619 - val_accuracy: 0.6484\n",
            "Epoch 220/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0524 - accuracy: 0.9856 - val_loss: 0.8195 - val_accuracy: 0.7188\n",
            "Epoch 221/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0591 - accuracy: 0.9848 - val_loss: 2.4728 - val_accuracy: 0.3281\n",
            "Epoch 222/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1014 - accuracy: 0.9675 - val_loss: 1.4724 - val_accuracy: 0.5391\n",
            "Epoch 223/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0901 - accuracy: 0.9757 - val_loss: 0.7319 - val_accuracy: 0.7500\n",
            "Epoch 224/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0595 - accuracy: 0.9811 - val_loss: 0.6948 - val_accuracy: 0.7344\n",
            "Epoch 225/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0583 - accuracy: 0.9843 - val_loss: 0.8999 - val_accuracy: 0.6719\n",
            "Epoch 226/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0705 - accuracy: 0.9778 - val_loss: 1.7371 - val_accuracy: 0.5234\n",
            "Epoch 227/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0671 - accuracy: 0.9827 - val_loss: 0.6284 - val_accuracy: 0.7656\n",
            "Epoch 228/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0491 - accuracy: 0.9881 - val_loss: 1.0831 - val_accuracy: 0.6562\n",
            "Epoch 229/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0559 - accuracy: 0.9848 - val_loss: 0.9740 - val_accuracy: 0.7422\n",
            "Epoch 230/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0713 - accuracy: 0.9761 - val_loss: 1.3840 - val_accuracy: 0.5625\n",
            "Epoch 231/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0730 - accuracy: 0.9753 - val_loss: 0.7851 - val_accuracy: 0.7656\n",
            "Epoch 232/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0634 - accuracy: 0.9806 - val_loss: 2.1120 - val_accuracy: 0.3984\n",
            "Epoch 233/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1007 - accuracy: 0.9708 - val_loss: 0.6338 - val_accuracy: 0.7344\n",
            "Epoch 234/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0594 - accuracy: 0.9835 - val_loss: 0.6120 - val_accuracy: 0.8047\n",
            "Epoch 235/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0537 - accuracy: 0.9852 - val_loss: 0.5570 - val_accuracy: 0.7891\n",
            "Epoch 236/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0669 - accuracy: 0.9815 - val_loss: 2.1708 - val_accuracy: 0.4688\n",
            "Epoch 237/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0499 - accuracy: 0.9876 - val_loss: 1.3395 - val_accuracy: 0.5703\n",
            "Epoch 238/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0830 - accuracy: 0.9736 - val_loss: 1.0975 - val_accuracy: 0.6406\n",
            "Epoch 239/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0495 - accuracy: 0.9852 - val_loss: 1.0294 - val_accuracy: 0.6953\n",
            "Epoch 240/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0741 - accuracy: 0.9782 - val_loss: 2.1360 - val_accuracy: 0.3906\n",
            "Epoch 241/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0888 - accuracy: 0.9716 - val_loss: 0.3186 - val_accuracy: 0.8906\n",
            "Epoch 242/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0576 - accuracy: 0.9864 - val_loss: 0.9098 - val_accuracy: 0.7188\n",
            "Epoch 243/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0559 - accuracy: 0.9852 - val_loss: 0.8405 - val_accuracy: 0.7266\n",
            "Epoch 244/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0553 - accuracy: 0.9860 - val_loss: 1.2953 - val_accuracy: 0.6250\n",
            "Epoch 245/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0873 - accuracy: 0.9724 - val_loss: 0.7086 - val_accuracy: 0.7891\n",
            "Epoch 246/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0475 - accuracy: 0.9868 - val_loss: 1.3252 - val_accuracy: 0.6641\n",
            "Epoch 247/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0488 - accuracy: 0.9876 - val_loss: 1.4793 - val_accuracy: 0.6094\n",
            "Epoch 248/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0688 - accuracy: 0.9811 - val_loss: 1.0012 - val_accuracy: 0.6641\n",
            "Epoch 249/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0599 - accuracy: 0.9794 - val_loss: 1.0900 - val_accuracy: 0.6094\n",
            "Epoch 250/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0639 - accuracy: 0.9831 - val_loss: 1.5793 - val_accuracy: 0.5078\n",
            "Epoch 251/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0392 - accuracy: 0.9914 - val_loss: 2.7563 - val_accuracy: 0.3906\n",
            "Epoch 252/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0825 - accuracy: 0.9708 - val_loss: 1.3074 - val_accuracy: 0.5859\n",
            "Epoch 253/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0520 - accuracy: 0.9831 - val_loss: 0.8457 - val_accuracy: 0.7578\n",
            "Epoch 254/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0628 - accuracy: 0.9835 - val_loss: 1.0265 - val_accuracy: 0.7031\n",
            "Epoch 255/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0881 - accuracy: 0.9671 - val_loss: 1.3119 - val_accuracy: 0.6641\n",
            "Epoch 256/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0421 - accuracy: 0.9852 - val_loss: 0.9021 - val_accuracy: 0.6719\n",
            "Epoch 257/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0488 - accuracy: 0.9876 - val_loss: 1.7892 - val_accuracy: 0.4141\n",
            "Epoch 258/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0591 - accuracy: 0.9835 - val_loss: 0.5834 - val_accuracy: 0.8281\n",
            "Epoch 259/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0517 - accuracy: 0.9852 - val_loss: 1.3118 - val_accuracy: 0.6484\n",
            "Epoch 260/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0471 - accuracy: 0.9893 - val_loss: 1.0908 - val_accuracy: 0.6797\n",
            "Epoch 261/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0979 - accuracy: 0.9679 - val_loss: 0.5603 - val_accuracy: 0.7969\n",
            "Epoch 262/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0528 - accuracy: 0.9868 - val_loss: 1.1647 - val_accuracy: 0.6484\n",
            "Epoch 263/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0384 - accuracy: 0.9918 - val_loss: 1.0023 - val_accuracy: 0.6797\n",
            "Epoch 264/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0567 - accuracy: 0.9852 - val_loss: 1.0743 - val_accuracy: 0.7188\n",
            "Epoch 265/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0560 - accuracy: 0.9831 - val_loss: 0.8695 - val_accuracy: 0.7109\n",
            "Epoch 266/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0446 - accuracy: 0.9876 - val_loss: 1.1407 - val_accuracy: 0.6641\n",
            "Epoch 267/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0772 - accuracy: 0.9736 - val_loss: 1.3176 - val_accuracy: 0.6562\n",
            "Epoch 268/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0668 - accuracy: 0.9790 - val_loss: 1.1917 - val_accuracy: 0.6328\n",
            "Epoch 269/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0540 - accuracy: 0.9839 - val_loss: 1.4257 - val_accuracy: 0.6250\n",
            "Epoch 270/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0492 - accuracy: 0.9864 - val_loss: 1.1956 - val_accuracy: 0.6250\n",
            "Epoch 271/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0578 - accuracy: 0.9823 - val_loss: 1.4394 - val_accuracy: 0.5547\n",
            "Epoch 272/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0672 - accuracy: 0.9769 - val_loss: 1.3133 - val_accuracy: 0.6016\n",
            "Epoch 273/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0630 - accuracy: 0.9761 - val_loss: 0.8391 - val_accuracy: 0.7500\n",
            "Epoch 274/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0509 - accuracy: 0.9864 - val_loss: 1.1605 - val_accuracy: 0.6641\n",
            "Epoch 275/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0476 - accuracy: 0.9872 - val_loss: 0.4428 - val_accuracy: 0.8672\n",
            "Epoch 276/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0622 - accuracy: 0.9811 - val_loss: 2.8388 - val_accuracy: 0.3672\n",
            "Epoch 277/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0563 - accuracy: 0.9839 - val_loss: 0.7545 - val_accuracy: 0.7656\n",
            "Epoch 278/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0467 - accuracy: 0.9864 - val_loss: 0.7644 - val_accuracy: 0.7266\n",
            "Epoch 279/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0739 - accuracy: 0.9753 - val_loss: 0.6437 - val_accuracy: 0.7891\n",
            "Epoch 280/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0501 - accuracy: 0.9835 - val_loss: 1.4092 - val_accuracy: 0.5703\n",
            "Epoch 281/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0717 - accuracy: 0.9757 - val_loss: 0.8634 - val_accuracy: 0.7500\n",
            "Epoch 282/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0480 - accuracy: 0.9852 - val_loss: 2.7098 - val_accuracy: 0.3281\n",
            "Epoch 283/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0563 - accuracy: 0.9815 - val_loss: 0.9690 - val_accuracy: 0.7266\n",
            "Epoch 284/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0489 - accuracy: 0.9856 - val_loss: 0.9500 - val_accuracy: 0.7500\n",
            "Epoch 285/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0656 - accuracy: 0.9761 - val_loss: 1.8513 - val_accuracy: 0.5547\n",
            "Epoch 286/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0459 - accuracy: 0.9876 - val_loss: 0.9645 - val_accuracy: 0.7188\n",
            "Epoch 287/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0530 - accuracy: 0.9827 - val_loss: 2.0775 - val_accuracy: 0.4688\n",
            "Epoch 288/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0549 - accuracy: 0.9848 - val_loss: 1.4316 - val_accuracy: 0.5625\n",
            "Epoch 289/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0441 - accuracy: 0.9885 - val_loss: 1.0279 - val_accuracy: 0.6797\n",
            "Epoch 290/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0439 - accuracy: 0.9864 - val_loss: 1.6428 - val_accuracy: 0.5234\n",
            "Epoch 291/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0654 - accuracy: 0.9786 - val_loss: 0.3456 - val_accuracy: 0.8828\n",
            "Epoch 292/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0711 - accuracy: 0.9802 - val_loss: 1.4005 - val_accuracy: 0.6172\n",
            "Epoch 293/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0650 - accuracy: 0.9778 - val_loss: 1.1463 - val_accuracy: 0.7188\n",
            "Epoch 294/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0480 - accuracy: 0.9881 - val_loss: 1.7872 - val_accuracy: 0.5000\n",
            "Epoch 295/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0404 - accuracy: 0.9885 - val_loss: 1.8709 - val_accuracy: 0.4609\n",
            "Epoch 296/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0463 - accuracy: 0.9868 - val_loss: 1.0884 - val_accuracy: 0.6328\n",
            "Epoch 297/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0507 - accuracy: 0.9839 - val_loss: 0.8976 - val_accuracy: 0.7344\n",
            "Epoch 298/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0401 - accuracy: 0.9872 - val_loss: 1.3450 - val_accuracy: 0.5859\n",
            "Epoch 299/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0368 - accuracy: 0.9918 - val_loss: 0.9404 - val_accuracy: 0.7266\n",
            "Epoch 300/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0695 - accuracy: 0.9790 - val_loss: 1.5389 - val_accuracy: 0.5469\n",
            "Epoch 301/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0398 - accuracy: 0.9901 - val_loss: 0.5656 - val_accuracy: 0.8125\n",
            "Epoch 302/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0533 - accuracy: 0.9848 - val_loss: 2.6747 - val_accuracy: 0.4609\n",
            "Epoch 303/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0392 - accuracy: 0.9876 - val_loss: 1.2616 - val_accuracy: 0.6406\n",
            "Epoch 304/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0486 - accuracy: 0.9860 - val_loss: 0.2880 - val_accuracy: 0.9219\n",
            "Epoch 305/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0635 - accuracy: 0.9823 - val_loss: 0.8561 - val_accuracy: 0.7969\n",
            "Epoch 306/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0368 - accuracy: 0.9930 - val_loss: 0.7101 - val_accuracy: 0.7500\n",
            "Epoch 307/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0334 - accuracy: 0.9918 - val_loss: 0.9812 - val_accuracy: 0.7656\n",
            "Epoch 308/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0597 - accuracy: 0.9786 - val_loss: 0.8589 - val_accuracy: 0.7812\n",
            "Epoch 309/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0440 - accuracy: 0.9872 - val_loss: 1.2024 - val_accuracy: 0.6484\n",
            "Epoch 310/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0482 - accuracy: 0.9852 - val_loss: 0.8807 - val_accuracy: 0.7500\n",
            "Epoch 311/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0416 - accuracy: 0.9893 - val_loss: 1.2363 - val_accuracy: 0.6953\n",
            "Epoch 312/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0511 - accuracy: 0.9868 - val_loss: 1.0806 - val_accuracy: 0.7344\n",
            "Epoch 313/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0362 - accuracy: 0.9909 - val_loss: 0.7462 - val_accuracy: 0.7812\n",
            "Epoch 314/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0603 - accuracy: 0.9815 - val_loss: 0.9010 - val_accuracy: 0.6953\n",
            "Epoch 315/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.1137 - accuracy: 0.9621 - val_loss: 0.7274 - val_accuracy: 0.8047\n",
            "Epoch 316/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0319 - accuracy: 0.9922 - val_loss: 1.6798 - val_accuracy: 0.5156\n",
            "Epoch 317/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0592 - accuracy: 0.9823 - val_loss: 0.7872 - val_accuracy: 0.7344\n",
            "Epoch 318/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0274 - accuracy: 0.9959 - val_loss: 1.6513 - val_accuracy: 0.5391\n",
            "Epoch 319/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0373 - accuracy: 0.9901 - val_loss: 1.0052 - val_accuracy: 0.6875\n",
            "Epoch 320/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0484 - accuracy: 0.9860 - val_loss: 1.0466 - val_accuracy: 0.6250\n",
            "Epoch 321/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0438 - accuracy: 0.9881 - val_loss: 1.2977 - val_accuracy: 0.6250\n",
            "Epoch 322/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0429 - accuracy: 0.9881 - val_loss: 1.4085 - val_accuracy: 0.6406\n",
            "Epoch 323/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0408 - accuracy: 0.9885 - val_loss: 1.9044 - val_accuracy: 0.4688\n",
            "Epoch 324/500\n",
            "243/243 [==============================] - 16s 65ms/step - loss: 0.0668 - accuracy: 0.9827 - val_loss: 1.4650 - val_accuracy: 0.5469\n",
            "Epoch 325/500\n",
            "243/243 [==============================] - 15s 63ms/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 0.6222 - val_accuracy: 0.8125\n",
            "Epoch 326/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0355 - accuracy: 0.9893 - val_loss: 2.0205 - val_accuracy: 0.4688\n",
            "Epoch 327/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0488 - accuracy: 0.9868 - val_loss: 1.1826 - val_accuracy: 0.6172\n",
            "Epoch 328/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0652 - accuracy: 0.9794 - val_loss: 3.9732 - val_accuracy: 0.3438\n",
            "Epoch 329/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0668 - accuracy: 0.9765 - val_loss: 0.9635 - val_accuracy: 0.6641\n",
            "Epoch 330/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0358 - accuracy: 0.9909 - val_loss: 0.9693 - val_accuracy: 0.7578\n",
            "Epoch 331/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0341 - accuracy: 0.9897 - val_loss: 0.7928 - val_accuracy: 0.7578\n",
            "Epoch 332/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0427 - accuracy: 0.9876 - val_loss: 1.2958 - val_accuracy: 0.6406\n",
            "Epoch 333/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0415 - accuracy: 0.9881 - val_loss: 1.7334 - val_accuracy: 0.4688\n",
            "Epoch 334/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0577 - accuracy: 0.9790 - val_loss: 1.4244 - val_accuracy: 0.6641\n",
            "Epoch 335/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0645 - accuracy: 0.9773 - val_loss: 1.1009 - val_accuracy: 0.7500\n",
            "Epoch 336/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0506 - accuracy: 0.9843 - val_loss: 1.8893 - val_accuracy: 0.5234\n",
            "Epoch 337/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0578 - accuracy: 0.9839 - val_loss: 1.9152 - val_accuracy: 0.5000\n",
            "Epoch 338/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0376 - accuracy: 0.9897 - val_loss: 0.8488 - val_accuracy: 0.7266\n",
            "Epoch 339/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0353 - accuracy: 0.9897 - val_loss: 0.8949 - val_accuracy: 0.7656\n",
            "Epoch 340/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0683 - accuracy: 0.9786 - val_loss: 2.3233 - val_accuracy: 0.4062\n",
            "Epoch 341/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0354 - accuracy: 0.9901 - val_loss: 0.7845 - val_accuracy: 0.7969\n",
            "Epoch 342/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0334 - accuracy: 0.9905 - val_loss: 0.6384 - val_accuracy: 0.7578\n",
            "Epoch 343/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0338 - accuracy: 0.9909 - val_loss: 1.4079 - val_accuracy: 0.5703\n",
            "Epoch 344/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0363 - accuracy: 0.9901 - val_loss: 2.5760 - val_accuracy: 0.3750\n",
            "Epoch 345/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0318 - accuracy: 0.9926 - val_loss: 0.6462 - val_accuracy: 0.7891\n",
            "Epoch 346/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0844 - accuracy: 0.9708 - val_loss: 0.7288 - val_accuracy: 0.8047\n",
            "Epoch 347/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0383 - accuracy: 0.9893 - val_loss: 0.9459 - val_accuracy: 0.7422\n",
            "Epoch 348/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0758 - accuracy: 0.9728 - val_loss: 1.0360 - val_accuracy: 0.7422\n",
            "Epoch 349/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0424 - accuracy: 0.9856 - val_loss: 0.6227 - val_accuracy: 0.7969\n",
            "Epoch 350/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0447 - accuracy: 0.9839 - val_loss: 1.0081 - val_accuracy: 0.6719\n",
            "Epoch 351/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0389 - accuracy: 0.9868 - val_loss: 1.7245 - val_accuracy: 0.4844\n",
            "Epoch 352/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0382 - accuracy: 0.9889 - val_loss: 1.7852 - val_accuracy: 0.5156\n",
            "Epoch 353/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0514 - accuracy: 0.9848 - val_loss: 0.9714 - val_accuracy: 0.6953\n",
            "Epoch 354/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0539 - accuracy: 0.9843 - val_loss: 1.2693 - val_accuracy: 0.6328\n",
            "Epoch 355/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0552 - accuracy: 0.9835 - val_loss: 1.4042 - val_accuracy: 0.5781\n",
            "Epoch 356/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0523 - accuracy: 0.9856 - val_loss: 0.5119 - val_accuracy: 0.8516\n",
            "Epoch 357/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0435 - accuracy: 0.9868 - val_loss: 0.9152 - val_accuracy: 0.7188\n",
            "Epoch 358/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0272 - accuracy: 0.9942 - val_loss: 0.9731 - val_accuracy: 0.6875\n",
            "Epoch 359/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0587 - accuracy: 0.9827 - val_loss: 1.2005 - val_accuracy: 0.7031\n",
            "Epoch 360/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0347 - accuracy: 0.9881 - val_loss: 0.8043 - val_accuracy: 0.7812\n",
            "Epoch 361/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0250 - accuracy: 0.9951 - val_loss: 1.0270 - val_accuracy: 0.7266\n",
            "Epoch 362/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0378 - accuracy: 0.9893 - val_loss: 1.2740 - val_accuracy: 0.7031\n",
            "Epoch 363/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0538 - accuracy: 0.9839 - val_loss: 0.9301 - val_accuracy: 0.7188\n",
            "Epoch 364/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0368 - accuracy: 0.9889 - val_loss: 1.5205 - val_accuracy: 0.5859\n",
            "Epoch 365/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0516 - accuracy: 0.9819 - val_loss: 1.5697 - val_accuracy: 0.6094\n",
            "Epoch 366/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0319 - accuracy: 0.9918 - val_loss: 2.4119 - val_accuracy: 0.4922\n",
            "Epoch 367/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0329 - accuracy: 0.9893 - val_loss: 0.7991 - val_accuracy: 0.7969\n",
            "Epoch 368/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0462 - accuracy: 0.9843 - val_loss: 0.9785 - val_accuracy: 0.7266\n",
            "Epoch 369/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0520 - accuracy: 0.9835 - val_loss: 1.3382 - val_accuracy: 0.6875\n",
            "Epoch 370/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0355 - accuracy: 0.9901 - val_loss: 0.9883 - val_accuracy: 0.6875\n",
            "Epoch 371/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0254 - accuracy: 0.9938 - val_loss: 0.7403 - val_accuracy: 0.7891\n",
            "Epoch 372/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0574 - accuracy: 0.9806 - val_loss: 0.9075 - val_accuracy: 0.7891\n",
            "Epoch 373/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0305 - accuracy: 0.9934 - val_loss: 1.8752 - val_accuracy: 0.4922\n",
            "Epoch 374/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0564 - accuracy: 0.9802 - val_loss: 1.7179 - val_accuracy: 0.5469\n",
            "Epoch 375/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0313 - accuracy: 0.9918 - val_loss: 3.0951 - val_accuracy: 0.3438\n",
            "Epoch 376/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0582 - accuracy: 0.9782 - val_loss: 0.8122 - val_accuracy: 0.7656\n",
            "Epoch 377/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0298 - accuracy: 0.9926 - val_loss: 0.5775 - val_accuracy: 0.8125\n",
            "Epoch 378/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0420 - accuracy: 0.9835 - val_loss: 1.6509 - val_accuracy: 0.5547\n",
            "Epoch 379/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 1.1263 - val_accuracy: 0.7188\n",
            "Epoch 380/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0320 - accuracy: 0.9914 - val_loss: 1.2723 - val_accuracy: 0.6953\n",
            "Epoch 381/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 1.2417 - val_accuracy: 0.6328\n",
            "Epoch 382/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0631 - accuracy: 0.9782 - val_loss: 1.6003 - val_accuracy: 0.6172\n",
            "Epoch 383/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0374 - accuracy: 0.9893 - val_loss: 1.3540 - val_accuracy: 0.6094\n",
            "Epoch 384/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0442 - accuracy: 0.9864 - val_loss: 1.2671 - val_accuracy: 0.6797\n",
            "Epoch 385/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0268 - accuracy: 0.9938 - val_loss: 1.3021 - val_accuracy: 0.6328\n",
            "Epoch 386/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0352 - accuracy: 0.9905 - val_loss: 1.7676 - val_accuracy: 0.5391\n",
            "Epoch 387/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0646 - accuracy: 0.9790 - val_loss: 0.9181 - val_accuracy: 0.7266\n",
            "Epoch 388/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0342 - accuracy: 0.9876 - val_loss: 0.9277 - val_accuracy: 0.7891\n",
            "Epoch 389/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0429 - accuracy: 0.9864 - val_loss: 1.0401 - val_accuracy: 0.6719\n",
            "Epoch 390/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0316 - accuracy: 0.9914 - val_loss: 0.6452 - val_accuracy: 0.8125\n",
            "Epoch 391/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0232 - accuracy: 0.9955 - val_loss: 1.0231 - val_accuracy: 0.6719\n",
            "Epoch 392/500\n",
            "243/243 [==============================] - 15s 63ms/step - loss: 0.0294 - accuracy: 0.9922 - val_loss: 0.8370 - val_accuracy: 0.7422\n",
            "Epoch 393/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0332 - accuracy: 0.9893 - val_loss: 1.1777 - val_accuracy: 0.7266\n",
            "Epoch 394/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0226 - accuracy: 0.9946 - val_loss: 1.3609 - val_accuracy: 0.5859\n",
            "Epoch 395/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0372 - accuracy: 0.9881 - val_loss: 1.2175 - val_accuracy: 0.6562\n",
            "Epoch 396/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 0.8588 - val_accuracy: 0.7188\n",
            "Epoch 397/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0488 - accuracy: 0.9831 - val_loss: 1.1831 - val_accuracy: 0.7500\n",
            "Epoch 398/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0415 - accuracy: 0.9885 - val_loss: 1.0443 - val_accuracy: 0.6562\n",
            "Epoch 399/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0208 - accuracy: 0.9971 - val_loss: 1.9268 - val_accuracy: 0.5234\n",
            "Epoch 400/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0282 - accuracy: 0.9930 - val_loss: 1.0987 - val_accuracy: 0.6641\n",
            "Epoch 401/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0458 - accuracy: 0.9864 - val_loss: 1.4196 - val_accuracy: 0.6250\n",
            "Epoch 402/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0715 - accuracy: 0.9773 - val_loss: 1.1331 - val_accuracy: 0.6875\n",
            "Epoch 403/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0169 - accuracy: 0.9971 - val_loss: 1.4051 - val_accuracy: 0.6094\n",
            "Epoch 404/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0542 - accuracy: 0.9811 - val_loss: 1.2892 - val_accuracy: 0.7031\n",
            "Epoch 405/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0769 - accuracy: 0.9806 - val_loss: 0.8612 - val_accuracy: 0.7578\n",
            "Epoch 406/500\n",
            "243/243 [==============================] - 16s 65ms/step - loss: 0.0390 - accuracy: 0.9876 - val_loss: 0.4710 - val_accuracy: 0.8672\n",
            "Epoch 407/500\n",
            "243/243 [==============================] - 15s 63ms/step - loss: 0.0292 - accuracy: 0.9934 - val_loss: 1.1474 - val_accuracy: 0.6250\n",
            "Epoch 408/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0353 - accuracy: 0.9885 - val_loss: 1.0896 - val_accuracy: 0.7422\n",
            "Epoch 409/500\n",
            "243/243 [==============================] - 16s 65ms/step - loss: 0.0429 - accuracy: 0.9881 - val_loss: 1.9219 - val_accuracy: 0.4531\n",
            "Epoch 410/500\n",
            "243/243 [==============================] - 16s 65ms/step - loss: 0.0425 - accuracy: 0.9864 - val_loss: 1.0808 - val_accuracy: 0.6875\n",
            "Epoch 411/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.7714 - val_accuracy: 0.8047\n",
            "Epoch 412/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0272 - accuracy: 0.9930 - val_loss: 1.5406 - val_accuracy: 0.5469\n",
            "Epoch 413/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0494 - accuracy: 0.9848 - val_loss: 2.6317 - val_accuracy: 0.3750\n",
            "Epoch 414/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.5365 - val_accuracy: 0.8516\n",
            "Epoch 415/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0266 - accuracy: 0.9946 - val_loss: 0.6151 - val_accuracy: 0.7891\n",
            "Epoch 416/500\n",
            "243/243 [==============================] - 15s 63ms/step - loss: 0.0494 - accuracy: 0.9860 - val_loss: 1.2424 - val_accuracy: 0.6328\n",
            "Epoch 417/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0388 - accuracy: 0.9868 - val_loss: 1.3440 - val_accuracy: 0.6172\n",
            "Epoch 418/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0483 - accuracy: 0.9852 - val_loss: 1.2218 - val_accuracy: 0.6875\n",
            "Epoch 419/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0387 - accuracy: 0.9876 - val_loss: 0.9035 - val_accuracy: 0.7969\n",
            "Epoch 420/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0315 - accuracy: 0.9918 - val_loss: 1.2195 - val_accuracy: 0.6719\n",
            "Epoch 421/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 1.4817 - val_accuracy: 0.5938\n",
            "Epoch 422/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0235 - accuracy: 0.9942 - val_loss: 1.1167 - val_accuracy: 0.6953\n",
            "Epoch 423/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0187 - accuracy: 0.9959 - val_loss: 1.0332 - val_accuracy: 0.6953\n",
            "Epoch 424/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0271 - accuracy: 0.9938 - val_loss: 1.6198 - val_accuracy: 0.5625\n",
            "Epoch 425/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0319 - accuracy: 0.9909 - val_loss: 1.3668 - val_accuracy: 0.5859\n",
            "Epoch 426/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0470 - accuracy: 0.9864 - val_loss: 1.4970 - val_accuracy: 0.6328\n",
            "Epoch 427/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0291 - accuracy: 0.9934 - val_loss: 0.6514 - val_accuracy: 0.8203\n",
            "Epoch 428/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0496 - accuracy: 0.9811 - val_loss: 1.1864 - val_accuracy: 0.6641\n",
            "Epoch 429/500\n",
            "243/243 [==============================] - 16s 65ms/step - loss: 0.0620 - accuracy: 0.9823 - val_loss: 1.3721 - val_accuracy: 0.6016\n",
            "Epoch 430/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0220 - accuracy: 0.9955 - val_loss: 1.0595 - val_accuracy: 0.7500\n",
            "Epoch 431/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0353 - accuracy: 0.9868 - val_loss: 1.0964 - val_accuracy: 0.7266\n",
            "Epoch 432/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0326 - accuracy: 0.9909 - val_loss: 0.8135 - val_accuracy: 0.7812\n",
            "Epoch 433/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0241 - accuracy: 0.9930 - val_loss: 0.7876 - val_accuracy: 0.7578\n",
            "Epoch 434/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0375 - accuracy: 0.9864 - val_loss: 0.8925 - val_accuracy: 0.7969\n",
            "Epoch 435/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0181 - accuracy: 0.9971 - val_loss: 1.2422 - val_accuracy: 0.6250\n",
            "Epoch 436/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0218 - accuracy: 0.9951 - val_loss: 2.0250 - val_accuracy: 0.4922\n",
            "Epoch 437/500\n",
            "243/243 [==============================] - 15s 63ms/step - loss: 0.0265 - accuracy: 0.9914 - val_loss: 1.4083 - val_accuracy: 0.5781\n",
            "Epoch 438/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0657 - accuracy: 0.9794 - val_loss: 1.4641 - val_accuracy: 0.5938\n",
            "Epoch 439/500\n",
            "243/243 [==============================] - 16s 65ms/step - loss: 0.0428 - accuracy: 0.9897 - val_loss: 1.0697 - val_accuracy: 0.7188\n",
            "Epoch 440/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0308 - accuracy: 0.9893 - val_loss: 2.5842 - val_accuracy: 0.3984\n",
            "Epoch 441/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0320 - accuracy: 0.9914 - val_loss: 0.8005 - val_accuracy: 0.7969\n",
            "Epoch 442/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0341 - accuracy: 0.9905 - val_loss: 0.7471 - val_accuracy: 0.7969\n",
            "Epoch 443/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0234 - accuracy: 0.9938 - val_loss: 1.1524 - val_accuracy: 0.6250\n",
            "Epoch 444/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0308 - accuracy: 0.9901 - val_loss: 0.9453 - val_accuracy: 0.7812\n",
            "Epoch 445/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0404 - accuracy: 0.9889 - val_loss: 1.8953 - val_accuracy: 0.5000\n",
            "Epoch 446/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0424 - accuracy: 0.9872 - val_loss: 1.0503 - val_accuracy: 0.7109\n",
            "Epoch 447/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0260 - accuracy: 0.9926 - val_loss: 0.4809 - val_accuracy: 0.8594\n",
            "Epoch 448/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0202 - accuracy: 0.9955 - val_loss: 0.9433 - val_accuracy: 0.7266\n",
            "Epoch 449/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0268 - accuracy: 0.9918 - val_loss: 1.2077 - val_accuracy: 0.6484\n",
            "Epoch 450/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0362 - accuracy: 0.9901 - val_loss: 0.8484 - val_accuracy: 0.7656\n",
            "Epoch 451/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0345 - accuracy: 0.9922 - val_loss: 3.1780 - val_accuracy: 0.3750\n",
            "Epoch 452/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0577 - accuracy: 0.9815 - val_loss: 1.0195 - val_accuracy: 0.6875\n",
            "Epoch 453/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0500 - accuracy: 0.9856 - val_loss: 1.5831 - val_accuracy: 0.6016\n",
            "Epoch 454/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0192 - accuracy: 0.9963 - val_loss: 0.9115 - val_accuracy: 0.7578\n",
            "Epoch 455/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.6797 - val_accuracy: 0.8125\n",
            "Epoch 456/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0137 - accuracy: 0.9979 - val_loss: 1.8683 - val_accuracy: 0.5312\n",
            "Epoch 457/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0553 - accuracy: 0.9843 - val_loss: 1.0526 - val_accuracy: 0.7344\n",
            "Epoch 458/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0544 - accuracy: 0.9823 - val_loss: 1.2778 - val_accuracy: 0.6484\n",
            "Epoch 459/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0232 - accuracy: 0.9946 - val_loss: 1.7672 - val_accuracy: 0.5156\n",
            "Epoch 460/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0244 - accuracy: 0.9930 - val_loss: 1.2529 - val_accuracy: 0.6953\n",
            "Epoch 461/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0306 - accuracy: 0.9918 - val_loss: 0.8656 - val_accuracy: 0.7656\n",
            "Epoch 462/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0497 - accuracy: 0.9852 - val_loss: 3.5094 - val_accuracy: 0.3203\n",
            "Epoch 463/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0323 - accuracy: 0.9897 - val_loss: 2.2450 - val_accuracy: 0.4688\n",
            "Epoch 464/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 0.8423 - val_accuracy: 0.7734\n",
            "Epoch 465/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0262 - accuracy: 0.9934 - val_loss: 1.8810 - val_accuracy: 0.5000\n",
            "Epoch 466/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 1.0178 - val_accuracy: 0.7578\n",
            "Epoch 467/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.8463 - val_accuracy: 0.7969\n",
            "Epoch 468/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0223 - accuracy: 0.9938 - val_loss: 0.6014 - val_accuracy: 0.8516\n",
            "Epoch 469/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0463 - accuracy: 0.9839 - val_loss: 2.8899 - val_accuracy: 0.5234\n",
            "Epoch 470/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0321 - accuracy: 0.9901 - val_loss: 1.3008 - val_accuracy: 0.6172\n",
            "Epoch 471/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 0.9030 - val_accuracy: 0.7578\n",
            "Epoch 472/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 1.2480 - val_accuracy: 0.6172\n",
            "Epoch 473/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0535 - accuracy: 0.9827 - val_loss: 1.0023 - val_accuracy: 0.7500\n",
            "Epoch 474/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0261 - accuracy: 0.9934 - val_loss: 1.1646 - val_accuracy: 0.6406\n",
            "Epoch 475/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0411 - accuracy: 0.9856 - val_loss: 1.1074 - val_accuracy: 0.7188\n",
            "Epoch 476/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0337 - accuracy: 0.9909 - val_loss: 1.3179 - val_accuracy: 0.6250\n",
            "Epoch 477/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0334 - accuracy: 0.9897 - val_loss: 0.7494 - val_accuracy: 0.8047\n",
            "Epoch 478/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0128 - accuracy: 0.9992 - val_loss: 1.2761 - val_accuracy: 0.7031\n",
            "Epoch 479/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0355 - accuracy: 0.9876 - val_loss: 2.3579 - val_accuracy: 0.4688\n",
            "Epoch 480/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0526 - accuracy: 0.9856 - val_loss: 0.7451 - val_accuracy: 0.7969\n",
            "Epoch 481/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.9372 - val_accuracy: 0.7500\n",
            "Epoch 482/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0643 - accuracy: 0.9765 - val_loss: 1.8717 - val_accuracy: 0.5156\n",
            "Epoch 483/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0322 - accuracy: 0.9909 - val_loss: 1.8515 - val_accuracy: 0.5234\n",
            "Epoch 484/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0247 - accuracy: 0.9934 - val_loss: 1.3874 - val_accuracy: 0.6328\n",
            "Epoch 485/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0180 - accuracy: 0.9955 - val_loss: 1.3192 - val_accuracy: 0.6797\n",
            "Epoch 486/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0877 - accuracy: 0.9732 - val_loss: 0.9478 - val_accuracy: 0.7344\n",
            "Epoch 487/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0229 - accuracy: 0.9946 - val_loss: 1.2695 - val_accuracy: 0.6172\n",
            "Epoch 488/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0426 - accuracy: 0.9864 - val_loss: 0.9692 - val_accuracy: 0.7031\n",
            "Epoch 489/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 1.5439 - val_accuracy: 0.5625\n",
            "Epoch 490/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.8785 - val_accuracy: 0.7734\n",
            "Epoch 491/500\n",
            "243/243 [==============================] - 15s 64ms/step - loss: 0.0228 - accuracy: 0.9959 - val_loss: 1.3758 - val_accuracy: 0.6016\n",
            "Epoch 492/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0443 - accuracy: 0.9827 - val_loss: 1.3525 - val_accuracy: 0.6094\n",
            "Epoch 493/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0218 - accuracy: 0.9946 - val_loss: 1.4039 - val_accuracy: 0.6016\n",
            "Epoch 494/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0267 - accuracy: 0.9934 - val_loss: 1.0811 - val_accuracy: 0.6641\n",
            "Epoch 495/500\n",
            "243/243 [==============================] - 16s 64ms/step - loss: 0.0272 - accuracy: 0.9922 - val_loss: 0.9974 - val_accuracy: 0.6719\n",
            "Epoch 496/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0265 - accuracy: 0.9926 - val_loss: 0.7321 - val_accuracy: 0.7969\n",
            "Epoch 497/500\n",
            "243/243 [==============================] - 16s 66ms/step - loss: 0.0433 - accuracy: 0.9868 - val_loss: 1.1765 - val_accuracy: 0.6875\n",
            "Epoch 498/500\n",
            "135/243 [===============>..............] - ETA: 6s - loss: 0.0297 - accuracy: 0.9926"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train, batch_size=10, epochs=500, validation_split=0.05,\n",
        "    validation_batch_size=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uALx6MeAjWJ"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0WFQmu9JXBy5"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Training Accuracy vs Validation Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LybJL2CWXJLv"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training Loss vs Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waLH596P5EHu"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "loss, acc = model.evaluate(x_train, y_train)\n",
        "print('Train')\n",
        "print(f'loss : {loss}')\n",
        "print(f'acc : {acc*100}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZKM9dXPUAcI"
      },
      "outputs": [],
      "source": [
        "# Test\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print('Test')\n",
        "print(f'loss : {loss}')\n",
        "print(f'acc : {acc*100}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predict"
      ],
      "metadata": {
        "id": "xdA-vMHvaCgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "pred = np.argmax(model.predict(x_test), axis=-1)"
      ],
      "metadata": {
        "id": "Q7GzTfV2aFTL",
        "outputId": "e972ba66-61a1-4e5f-b4ef-673fd51fa7a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 146ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBTiYBxOccy1",
        "outputId": "86c854bd-adb9-4a19-9259-6ae5a09c72e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 4 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 3 5 3 5 5 6 3 5 5 5 5 5 5 6\n",
            " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
            " 6 6 6 6 6 6 6 1 1]\n"
          ]
        }
      ],
      "source": [
        "print(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULue0gi7Hlub"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QeXQFvyNehF"
      },
      "outputs": [],
      "source": [
        "model.save('/content/model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(\"/content/model.h5\",\"/content/drive/MyDrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F-09qPt0AAyd",
        "outputId": "a2afda6b-aeca-45dd-901a-3630cb55d095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/model3label.h5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQuhZZt3OGOp"
      },
      "source": [
        "##Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmD22NXLODLq"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZvr6uU-PL2Y"
      },
      "outputs": [],
      "source": [
        "model = load_model('/content/drive/MyDrive/model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZdCmW28PgKQ"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqVFOvN7kVhj"
      },
      "source": [
        "# Apply prescription"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imports"
      ],
      "metadata": {
        "id": "fxa0e9BqwAY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "US5_c0lrd_7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Read Image &  Resize"
      ],
      "metadata": {
        "id": "JK5E-MltwHWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Threshold Function"
      ],
      "metadata": {
        "id": "aTt4uBwxwOXN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVP5MBSmEx2A"
      },
      "outputs": [],
      "source": [
        "def thresholding(image):\n",
        "    blurred_img = cv2.GaussianBlur(image.copy(), (17, 17), 0)\n",
        "    gray_img = cv2.cvtColor(blurred_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply adaptive thresholding\n",
        "    threshold_value = 255\n",
        "    max_binary_value = cv2.THRESH_BINARY_INV\n",
        "    threshold_type = cv2.ADAPTIVE_THRESH_GAUSSIAN_C\n",
        "    block_size = 11\n",
        "    constant = 2\n",
        "    thresh_img = cv2.adaptiveThreshold(gray_img, threshold_value, threshold_type, max_binary_value, block_size, constant)\n",
        "\n",
        "    # Display the thresholded image\n",
        "    plt.imshow(thresh_img, cmap='gray')\n",
        "\n",
        "    return thresh_img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Remove Header And Footer Function"
      ],
      "metadata": {
        "id": "2x4eufSTYaKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_header_footer(image):\n",
        "    # Thresholding\n",
        "    thresh_img = thresholding(image)\n",
        "\n",
        "    # Find and Sort Contours for the full image\n",
        "    contours, hierarchy = cv2.findContours(thresh_img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    sorted_contours = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[1])  # Sort vertically\n",
        "\n",
        "    # Specific cutting contours\n",
        "    img_width = image.shape[1]  # Width of the image\n",
        "    contours_for_cut = []\n",
        "    for ctr in sorted_contours:\n",
        "        x, y, w, h = cv2.boundingRect(ctr)\n",
        "        if w > (img_width * 0.80):\n",
        "            contours_for_cut.append((x, y, w, h))\n",
        "\n",
        "    # Crop contours from image\n",
        "    cropped_img = image.copy()\n",
        "    if len(contours_for_cut) > 1:\n",
        "        x = 0\n",
        "        w = cropped_img.shape[1]\n",
        "\n",
        "        # Remove header\n",
        "        h = cropped_img.shape[0]\n",
        "        header_y = contours_for_cut[0][1]\n",
        "        header_h = contours_for_cut[0][3]\n",
        "        header = header_y + header_h\n",
        "        y = header\n",
        "        cropped_img = cropped_img[y:h, x:w]\n",
        "\n",
        "        # Remove footer\n",
        "        new_y = 0\n",
        "        h_without_header = cropped_img.shape[0]\n",
        "        footer_y = contours_for_cut[-1][1]\n",
        "        footer_h = contours_for_cut[-1][3]\n",
        "        footer = h - footer_y\n",
        "        new_h = h_without_header - footer\n",
        "        cropped_img = cropped_img[new_y:new_h, x:w]\n",
        "\n",
        "        plt.imshow(cropped_img)\n",
        "\n",
        "    return cropped_img\n"
      ],
      "metadata": {
        "id": "cfLjGoRKYaXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mean Hight Of Lines function"
      ],
      "metadata": {
        "id": "MWashzs9SBYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_height_of_lines(sorted_contours_lines):\n",
        "    sum_of_heights = 0\n",
        "    for ctr in sorted_contours_lines:\n",
        "        x, y, w, h = ctr\n",
        "        sum_of_heights += h\n",
        "    mean_of_heights = sum_of_heights / len(sorted_contours_lines)\n",
        "    return mean_of_heights\n"
      ],
      "metadata": {
        "id": "gjzhXk5xSBoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mean Space Between Lines function"
      ],
      "metadata": {
        "id": "yYK_hdYXUQl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_space_between_lines(sorted_contours_lines):\n",
        "    sum_of_spaces = 0\n",
        "    i = 1\n",
        "    for ctr in sorted_contours_lines:\n",
        "        if i < len(sorted_contours_lines):\n",
        "            x, y, w, h = ctr\n",
        "            nx, ny, nw, nh = sorted_contours_lines[i]\n",
        "            sum_of_spaces += ny - (y + h)\n",
        "            i += 1\n",
        "    mean_of_spaces = sum_of_spaces / (len(sorted_contours_lines) - 1)\n",
        "    return mean_of_spaces\n"
      ],
      "metadata": {
        "id": "Cc9VBe4zUQ0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Contours to (x, y, w, h) function"
      ],
      "metadata": {
        "id": "c8mAadTSwYJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def contours_to_xywh(sorted_contours_lines_N):\n",
        "  sorted_contours_lines = []\n",
        "  for ctr in sorted_contours_lines_N:\n",
        "    x,y,w,h = cv2.boundingRect(ctr)\n",
        "    sorted_contours_lines.append((x,y,w,h))\n",
        "  print(sorted_contours_lines)\n",
        "  return(sorted_contours_lines)"
      ],
      "metadata": {
        "id": "HB-VkavclnLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##remove noise function"
      ],
      "metadata": {
        "id": "FjFpClVkzUzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_noise(img4, sorted_contours_lines, mean_of_heights):\n",
        "  sorted_contours_lines_mean = []\n",
        "  for ctr in sorted_contours_lines:\n",
        "    x,y,w,h = ctr\n",
        "    if(h < int(mean_of_heights/2)):\n",
        "        continue\n",
        "    cv2.rectangle(img4, (x,y), (x+w, y+h), (np.random.randint(255),np.random.randint(255),np.random.randint(255)), 5) #img, coordnate, area, color, bold\n",
        "    sorted_contours_lines_mean.append((x,y,w,h))\n",
        "  return sorted_contours_lines_mean"
      ],
      "metadata": {
        "id": "6CCMgqovxdJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##get contours of line segmentation function"
      ],
      "metadata": {
        "id": "VxdPw-H92s9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_contours_line_segmentation(thresh_img):\n",
        "    #line delation\n",
        "  kernel = np.ones((5,200), np.uint8) #matrix of ones on shape 3*85 in dataType unsigned int\n",
        "  dilated = cv2.dilate(thresh_img, kernel, iterations = 1) #iteration is num of steps of kernal\n",
        "  # plt.imshow(dilated, cmap='gray')\n",
        "\n",
        "  #get contours\n",
        "  (contours, heirarchy) = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "  sorted_contours_lines_N = sorted(contours, key = lambda ctr : cv2.boundingRect(ctr)[1]) # (x, y, w, h) #1 mean sort vertically but 0 mean sort horizontally\n",
        "\n",
        "  sorted_contours_lines = contours_to_xywh(sorted_contours_lines_N)\n",
        "\n",
        "  return sorted_contours_lines"
      ],
      "metadata": {
        "id": "OWEG4UIA2y8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Line segmentation function"
      ],
      "metadata": {
        "id": "sN5a6H39kaY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def line_segmentation(thresh_img, cutted_img):\n",
        "\n",
        "  sorted_contours_lines = get_contours_line_segmentation(thresh_img)\n",
        "  #First Calling Of Mean Hight & Mean Space**(Before Delete Noise)\n",
        "  mean_of_heights = mean_height_of_lines(sorted_contours_lines)\n",
        "  mean_of_spaces = mean_space_between_lines(sorted_contours_lines)\n",
        "  print(mean_of_heights)\n",
        "  print(mean_of_spaces)\n",
        "\n",
        "\n",
        "  #remove noise and drow line segmentation on cutted_img\n",
        "  sorted_contours_lines_mean = remove_noise(cutted_img, sorted_contours_lines, mean_of_heights)\n",
        "  plt.imshow(cutted_img);\n",
        "\n",
        "  return sorted_contours_lines_mean"
      ],
      "metadata": {
        "id": "0EhuK_yrkevj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##space between word function"
      ],
      "metadata": {
        "id": "uHE7rgnU8uSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spaceBetweenWords(word1, word2):\n",
        "  x, y, w, h = cv2.boundingRect(word1)\n",
        "  x2, y2, w2, h2 = cv2.boundingRect(word2)\n",
        "  space=x2-(w+x)\n",
        "  print(f\"x1 {x} x2 {x2}\")\n",
        "  return space"
      ],
      "metadata": {
        "id": "pOp_7CMx8yKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##average  x function"
      ],
      "metadata": {
        "id": "rlpG9ApO86ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def average_x(sorted_contours_lines_mean):\n",
        "  avgX = 0\n",
        "  sumX = 0\n",
        "  for line in sorted_contours_lines_mean:\n",
        "    sumX += line[0]\n",
        "    print(f\"{line}  {sumX}\")\n",
        "  avgX = sumX/len(sorted_contours_lines_mean)\n",
        "  print(avgX *1.4)\n",
        "  return avgX"
      ],
      "metadata": {
        "id": "KIgBlLsO89Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Word segmentation function"
      ],
      "metadata": {
        "id": "8LGSGDjaE_DW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_segmentation(thresh_img, cutted_img, sorted_contours_lines_mean):\n",
        "  kernel = np.ones((1,16), np.uint8)\n",
        "  dilated2 = cv2.dilate(thresh_img, kernel, iterations = 4)\n",
        "  plt.imshow(dilated2, cmap='gray');\n",
        "  img3 =cutted_img.copy()\n",
        "  img4 = cutted_img.copy()\n",
        "  # words_list = []\n",
        "  ln=0\n",
        "  FistWordList = []\n",
        "  FR=0\n",
        "  avgX = average_x(sorted_contours_lines_mean)\n",
        "  for line in sorted_contours_lines_mean:\n",
        "    sorted_contour_words = []\n",
        "    if line[0] > (avgX*0.5) :#line[0]=x #if exist more than word in exact line  لو الاكس كبيره يبقي السطر بادئ مش من اول السطر فمش عايزه\n",
        "      continue\n",
        "    FirstWordInLine=0\n",
        "\n",
        "    x, y, w, h = line\n",
        "\n",
        "    roi_line = dilated2[y:h+y, x:w+x]\n",
        "\n",
        "    # draw contours on each word\n",
        "    (cnt, heirarchy) = cv2.findContours(roi_line.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    sorted_contour_words_beforeFilter = sorted(cnt, key=lambda cntr : cv2.boundingRect(cntr)[0])#0 mean sort horizontally but 1 mean sort vertically\n",
        "\n",
        "    for word in sorted_contour_words_beforeFilter:\n",
        "        if cv2.contourArea(word) < 400:\n",
        "            continue\n",
        "        sorted_contour_words.append(word)\n",
        "\n",
        "    for word in sorted_contour_words:\n",
        "\n",
        "        if FR==0 :\n",
        "          firstR = word\n",
        "          FR=1\n",
        "        if (ln >= 0) and (FirstWordInLine == 0) and len(sorted_contour_words)>1:\n",
        "            spaceBetweenWord=spaceBetweenWords(sorted_contour_words[0], sorted_contour_words[1])\n",
        "            FistWordList.append(((x, y), word, spaceBetweenWord))\n",
        "            FirstWordInLine = 1\n",
        "\n",
        "\n",
        "        x2, y2, w2, h2 = cv2.boundingRect(word)\n",
        "        # words_list.append([x+x2, y+y2, x+x2+w2, y+y2+h2])\n",
        "        cv2.rectangle(img3, (x+x2, y+y2), (x+x2+w2, y+y2+h2), (np.random.randint(255),np.random.randint(255),np.random.randint(255)),6)\n",
        "    ln+=1\n",
        "\n",
        "  plt.imshow(img3)\n",
        "\n",
        "  contours_R = []\n",
        "\n",
        "  AreaR1 = cv2.contourArea(FistWordList[0][1]) #FistWordList[num of word][contours of word]##contour of first word in list\n",
        "\n",
        "  if(AreaR1 < (cv2.contourArea(firstR)*3)) :\n",
        "    for word in FistWordList:\n",
        "      ##word -> word[0]= contours of line, word[1]=contour of word in the line, word[2]= space between first & second\n",
        "      print(cv2.contourArea(word[1])) #word[1]=contour of word\n",
        "      if (cv2.contourArea(word[1]) < (AreaR1+(AreaR1*1.5))  ):\n",
        "        x2, y2, w2, h2 = cv2.boundingRect(word[1])\n",
        "        #word is (x, y), word----->(x, y) of line of word ,,, word is contour of words\n",
        "        #word[1] = contour of word\n",
        "        #word[0][0] = x of line,,,,word[0][1] = y of line\n",
        "        cv2.rectangle(img4, (word[0][0]+x2, word[0][1]+y2), (word[0][0]+x2+w2, word[0][1]+y2+h2), (np.random.randint(255),np.random.randint(255),np.random.randint(255)),6)\n",
        "        contours_R.append((word[0][0]+x2, word[0][1]+y2, w2, h2))\n",
        "\n",
        "  plt.imshow(img4);\n",
        "  return contours_R"
      ],
      "metadata": {
        "id": "myv9QR0RBay5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##mean start R\\"
      ],
      "metadata": {
        "id": "y053nbX_FWnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def avgRR(contors):\n",
        "  avgR = 0\n",
        "  sumR = 0\n",
        "  for R in contors:\n",
        "    sumR += (R[0] + R[2]) #x+w\n",
        "    # print(f\"{line}  {sumR}\")\n",
        "  avgR = sumR/len(contors)\n",
        "  print(avgR)\n",
        "  return avgR"
      ],
      "metadata": {
        "id": "Dz-dgXRQFgk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Remove R\\"
      ],
      "metadata": {
        "id": "k6breZnRJPFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_R(imgR, contours_R):\n",
        "  avgR = avgRR(contours_R)\n",
        "  x, y, w, h = contours_R[0]\n",
        "  # if( (x+w) < avgR):\n",
        "  # cv2.rectangle(imgR, (x, y), (x+w, y+h), (np.random.randint(255),np.random.randint(255),np.random.randint(255)),9)\n",
        "  n_y=0\n",
        "  n_h=imgR.shape[0]\n",
        "  n_x=int(avgR)\n",
        "  n_w = imgR.shape[1]\n",
        "  im = imgR[n_y:n_h, n_x:n_w]\n",
        "\n",
        "  plt.imshow(im);\n",
        "  return im"
      ],
      "metadata": {
        "id": "LfXJ0WsEJRDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Word detection after remove R\\"
      ],
      "metadata": {
        "id": "CLb-x9MaLHEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def final_word_detection(im):\n",
        "  thresh_img = thresholding(im)\n",
        "  kernel = np.ones((1,60), np.uint8)\n",
        "  dilated5 = cv2.dilate(thresh_img, kernel, iterations = 1)\n",
        "  plt.imshow(dilated5, cmap='gray');\n",
        "\n",
        "  (contours, heirarchy) = cv2.findContours(dilated5.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "  sorted_contours_Word_N = sorted(contours, key = lambda ctr : cv2.boundingRect(ctr)[1]) # (x, y, w, h) #1 mean sort vertically but 0 mean sort horizontally\n",
        "  # print(sorted_contours_lines_N[0].shape)\n",
        "\n",
        "  sorted_contours_Words = []\n",
        "  for ctr in sorted_contours_Word_N:\n",
        "    x,y,w,h = cv2.boundingRect(ctr)\n",
        "    sorted_contours_Words.append((x,y,w,h))\n",
        "\n",
        "  img4 = im.copy()\n",
        "  sorted_contours_Words_mean = []\n",
        "  for ctr in sorted_contours_Words:\n",
        "\n",
        "    #ctr= sorted_contours_lines[4]\n",
        "    x,y,w,h = ctr\n",
        "    if (w * h) < 2000:\n",
        "      continue\n",
        "\n",
        "    cv2.rectangle(img4, (x,y), (x+w, y+h), (np.random.randint(255),np.random.randint(255),np.random.randint(255)), 5) #img, coordnate, area, color, bold\n",
        "    sorted_contours_Words_mean.append((x,y,w,h))\n",
        "  plt.imshow(img4);\n",
        "  return sorted_contours_Words_mean"
      ],
      "metadata": {
        "id": "bNg7GlS9LLsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %rm -rf /content/Words.zip\n",
        "# !zip -r /content/Words.zip /content/Words/ #path+name  #path⅖"
      ],
      "metadata": {
        "id": "9tJqwyYMN8iE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "580f3c59-ac09-40de-af8c-1bda7feb8a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/Words/ (stored 0%)\n",
            "  adding: content/Words/Word_0.jpg (deflated 3%)\n",
            "  adding: content/Words/Word_2.jpg (deflated 3%)\n",
            "  adding: content/Words/Word_9.jpg (deflated 2%)\n",
            "  adding: content/Words/Word_8.jpg (deflated 4%)\n",
            "  adding: content/Words/Word_1.jpg (deflated 1%)\n",
            "  adding: content/Words/Word_6.jpg (deflated 5%)\n",
            "  adding: content/Words/Word_3.jpg (deflated 4%)\n",
            "  adding: content/Words/Word_5.jpg (deflated 1%)\n",
            "  adding: content/Words/Word_4.jpg (deflated 2%)\n",
            "  adding: content/Words/Word_7.jpg (deflated 3%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run(original_img):\n",
        "  cutted_img = remove_header_footer(original_img)\n",
        "  thresh_img = thresholding(cutted_img)\n",
        "\n",
        "  sorted_contours_lines_mean = line_segmentation(thresh_img.copy(), cutted_img.copy())\n",
        "  #calc mean height and mean spaces after remove noise and line segmentation\n",
        "  mean_of_heights = mean_height_of_lines(sorted_contours_lines_mean)\n",
        "  mean_of_spaces = mean_space_between_lines(sorted_contours_lines_mean)\n",
        "\n",
        "  contours_R = word_segmentation(thresh_img.copy(), cutted_img.copy(), sorted_contours_lines_mean)\n",
        "\n",
        "  im = remove_R(cutted_img.copy(), contours_R)\n",
        "\n",
        "  sorted_contours_Words_mean = final_word_detection(im.copy())\n",
        "\n",
        "\n",
        "  crop_img = im.copy()\n",
        "  i=0\n",
        "  %rm -rf /content/Words\n",
        "  os.mkdir('/content/Words')\n",
        "  for ctr in sorted_contours_Words_mean:\n",
        "\n",
        "    x,y,w,h = ctr\n",
        "    #x,y,w,h = cv2.boundingRect(ctr)\n",
        "    word = crop_img[y:h+y, x:w+x]\n",
        "    print(str(x) + \" \" + str(y) +\" \"+str(w) +\" \"+str(h))\n",
        "    cv2.imwrite(f\"/content/Words/Word_{i}.jpg\", word)\n",
        "    i+=1\n"
      ],
      "metadata": {
        "id": "nec4ITgtct0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "ZZKeByKnELKh",
        "outputId": "3c98619e-799a-4f53-b6e3-60020f8cd6bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0, 1996, 138), (0, 0, 299, 17), (1073, 20, 201, 5), (124, 22, 200, 5), (0, 29, 1237, 67), (1354, 99, 200, 5), (97, 106, 200, 6), (219, 279, 902, 234), (1309, 712, 229, 10), (1418, 728, 201, 5), (206, 785, 986, 345), (0, 813, 118, 16), (599, 1715, 200, 6), (0, 1777, 166, 5)]\n",
            "61.714285714285715\n",
            "70.61538461538461\n",
            "(0, 0, 1996, 138)  0\n",
            "(0, 29, 1237, 67)  0\n",
            "(219, 279, 902, 234)  219\n",
            "(206, 785, 986, 345)  425\n",
            "148.75\n",
            "x1 0 x2 82\n",
            "x1 101 x2 104\n",
            "25343.0\n",
            "12545.5\n",
            "1573.5\n",
            "290 0 112 110\n",
            "0 20 167 59\n",
            "0 112 403 18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJgAAAGiCAYAAAAbVA9eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB8nUlEQVR4nO29fbglVXUm/u6qc+7t2w3d0CCNHUGJSUSERAOIREdN5JEoJhJ1EieOcWb86cRp/MIh6DNKokkkOhm/FWKeiTgzOGZ8JibqRJRBRaP4BSEqKiZqbCJpQIFuoLvvOadq//6oWlXvfmvVuec6fbvx9F3N5ZxTtWvvXbVXrfWuj713iDFGrNM6rRFlh7oD6zTftM5g67SmtM5g67SmtM5g67SmtM5g67SmtM5g67SmtM5g67SmtM5g67SmtM5g67SmtM5g67SmdL9msHe+8514yEMegg0bNuCss87CF7/4xUPdpXVaJd1vGezP//zPceGFF+J3f/d3ccMNN+Dnfu7ncO655+L2228/1F1bp1VQuL8Gu8866yyceeaZeMc73gEAKMsSJ5xwAl784hfjla985SHu3TrNSoND3QGPRqMRrr/+erzqVa9qjmVZhnPOOQfXXXede83y8jKWl5eb32VZ4s4778QxxxyDEMKa9/lwoxgj7rnnHmzfvh1Z1q8I75cM9oMf/ABFUWDbtm3J8W3btuGb3/yme82ll16K1772tQeje+tEdMstt+BBD3pQ7/n7JYP9KPSqV70KF154YfN79+7dOPHEE/GSl74YS0tLiDEixogQAoqiQFmWGA6HKIoCMUYURYHBYIDxeAwAKIoieTNDCCjLEmVZopgUiIgY5DliEVEUE4QsA2JEluWI9b8yRmQhA0JAjCUmkwmKokAoI/LBAAHAeFJgYXERy8vLKMoCMZbI8xxZlmE8HqMsq98hAlkIiDECIWBSFigmBbI8w8JwERvv3Y+fuP0ufPf4o7F/YYCiKLCwsIDRaARDQSbJY4zIsgxlWWIwGKAoS4wnEwzyHA8/5RQ8oJb6MUaUZQksj3DvVZ/C8GEPxYaH/xQAYN++ffid3/kdHHnkkVPH5X7JYMceeyzyPMdtt92WHL/ttttw/PHHu9csLi5icXGxc/yeE4/AaOMSGGqWZUQIlRo1psuyDMPhEKPRCEVRAqjK53mOekwxmUwQY8RkMsHCwgIKAGVRNvXGGBEyG5iILM8qxi5KLN56DwZ7gaWlJaAsrXpkeYHFDRuQZRlGoxFCBgyHQ0wmEwAVUwyHQ0xGYwzyvGLyGBFihk2bNgEAxuMJMkRsGAwxHAwQFxcxHo+RZRkGg0HzcgwGA0wmk4Z5sixDnudVPxYXUZYlFhYWsLi4iCzLmmdTZjkmgyE2bNiA4YYNybNcCX7cLxlsYWEBp59+Oq655hqcf/75ACpmuOaaa3DBBResqq67jlvAYGkIoJVgFVVSBSEgAO25sAGoH2Cs/9c+w8WKYQDsrSViXg860P+wi2GGjTlw1Lf3IAsZJsUEWZ4jhIqBTVJleZb00+qbTCZAAMbjMRYXFzGajJGFrBnoPMsbRrHP4XCI5eXlhsEWFhYwmUwwGAya52lSPdZtLC4uNi8b6mfCzJQ+v9nofslgAHDhhRfiec97Hs444ww8+tGPxlve8hbcd999+Lf/9t+uqp6Tv1sgC/sQY4lYRoRg6mcEBGDLli0Yj8coJhNs2rQJRVFgUhTYs+cejJaXcdTRR2PTxo0YTybYt28v9u7di+XlETYuLWFpaQkLgwx33nkn9u/fj4WFBSCaagxACBjHAneccRyKrBrEMiuBLKCo+4NYDdjCwgKWl5cbCZhlWSNFTE1mWYZJLBGyrKofFaMEZACq3+PJGMWgZvaQqsMQAiaTSSO5TGXHGJFnGfbu3QvUTDUYDGp1DJSopXTNW6thsvstg/3Gb/wG7rjjDlxyySXYtWsXHvnIR+Kqq67qAP8VaVRgOMhQFLVUABAnBSb37cNx247Dnbf9ANu2bcO+yT5871vfRlmWWFpawpYtW1BmQxwxWMTXbvg7DIdDbN++HUcOl3DMpi0IIeCWnTsxGU1w0kkn4Qf7f4AwLjEajRopUpYl8kEGRCCvBzXLMoQQKnUYAsqywHC4AAAYDAcoy6LBeqPRqJE4eZ6jKAoUNYOYZKkYqJV2sda9k8kEeZZV1xQFFhcr6bt//35s3LgR+/fvb9RmludACMhr9WtMHUJARAsBKmkeEqm2Et1vHa0AcMEFF+B73/selpeX8YUvfAFnnXXWqusoJ0UD3CuRX9aqbYCyLPGtb30Lk8kEV111FcqyxF133YUbbrgBo9EIW7ZswUc/+lHs3bsXk8kEN954I7J60CaTCb7xjW/gtttuw4YNGyrwXxsG9vbzYNj3GCPG43FjWDBD2u/xeIz9+/djw4YNjYpL7yE2GI0ZDUCjOofDYWUcEFgfj8dYWFhAlmUN1gohIAsBS0tL2LhxIwDDnaSqa9EVspD0YRa6XzPYgaAsBOQhA8qIclIAqN72Y445BvfsuQdHHHEEFhYW8BM/8RP4mZ9+GLYefQzu/OFdOPKIzdiz+x58//u34qE/+VM44UEn4J9u+T7uuP0O7Nu3D5s2bcIRRxyJDRsWUeGmsrFOTe1kWWVBIqBSm7UUi0WJhcEQGSqGMEtvMplUkifPMRwOG6YIITRMOxwOEUJomKcoCiwvL1cqP6LClajw2qSoMJfVZe1XDB0qYwcZsmyA0WhcM3713OxeYokGhJZl9VIALdZb8fkf0NG8H9JoPK6YjFRUlmXYsGEDvn/rrdi2bRsWFxfxmLMeg82bN+M73/kOtm7dimOOOQZ33nknNixuwKZNm7CwsIjRaIQ99+xp1BwQm8E2qy3LssZSG4/HrbVYW4NFUVSWHlmSBrgXhkMcccQRyPO8kTQmgfbt24fRaITJZFIxz2SSGBfD4RAIaNStgXWzIPM8b9TteDxGWRQVBqzbrxgnNIwzGAwaSVZMiko91vWyYbMS3W8x2IGihYX2gQ/yHEUZGwxz11134uSTH4Z//ud/Rp4PcM8992L37t04//zzK2xSuy7s+rIskWd5A5YrKVA96KIosLS0lDz4PM+B3N7hiuGKogDKCNTqZzgcNlZcURbI86yRTkBruRmzZFnWuGP27dtXlUWGLCvqfkwQQ9YwwXhSqdbRaJRYh2Vd72AwqCRU7aeze7F7NoZCaH+bdJuF5l6ClWVB38sG49x9991YXFhsHJoblzbis5/9LJ7whCdgcXERP/zhD7D1mK1YXFzAeDzCvv37AERs27YtGQh72Iu174kxVwgBkdwBk8kEZVFhwjLWztYaoJtKtcE1lWZSJ9R/iBHjWp2xI7gsIxCByaTqj0k6k7KDQZ5gp+FwiOFwUFuaZdNuUUw6zG3E108LDzHNvQTL0L51le8rYvPmzfjmN7+Jbdu2YcOGDTjqqKPw0Y9+FHfeeSdCCPj0pz+NJ53zS1hcXMSJDz4Rd951J3bt2oWHnPQQbD1mK/bt24fxeIw99+xBHrbgnnvuwdFHH4277rqrsfaAWvXVA2Q+r1FRIAYgHw4wmoyxvDzC4kLtIK5Vpg1q5fQtqt8RlVpFQBlLhLxVn5XVWbXJatGYczDIMRqNgBgaX1gIAeMa71n/TFWaSjXV7UmrWUH+3DOYvYU28IZt9u7diwc96Cewf/9+3HfffTjjjNMbyzKEyuN+11134dRTT8U999yDk046Cdu2bcNtt92Go48+GmVZ4pwnnYPJaIQjjzwSu3fvTtwHpn4mMAduaI5bvwBgULfJkmo8HieMmmUZskHApHbIgnBVlmUoYtnUa1LP3AzGNJVEzRI1aareDAGToBoia6RYaKXtrDT3DBZqzFTGWHnPayZ41KMehQ1Li9izZw+WlpawYcNS5a8a5CiLAj+884c1TrsLmzdvRowRP/zhD3HvvfdiNBphaWmpsiaXNuLWf74V995zb2PhGdgvy7KKSsYWcwFI8FS2kGNhuNC4KCbFuCljLo2FhQWECOSDARaGQ+xfXiYGKZCFDFlW4aQWsKfeesAkYEWTyQT7l5cxqC1WY8LFxcUqPlkzmie97P5moblnsN0bI8YbAqoXv3oD9y+MMRwO8cP992C8MMFksh9FUSDPcsRxRJ7lKLYsIMYS+5eX8cN9P6zAfR4Qj1lCzHPsLccYbNiAbMMQe/dOgE2bMckyTCh8NCkKlIiIeWisSmOuRlLUaovB/MLCQsUYZaykTsgwKYpK1Y0nyPIBAio8CVTOVRMy7CSt1CoaQA+0zB2yDFk+ALIMy+NJg9NGo3ESo2Xpa767PsbzaO4Z7JaHbsBwYzcIDhQAhvVfBX+8AEjkk6YZQvKBGI9IrgnBwpn1hQEIeytJxBLGJEsbMI+NBZllOfJ8AKBAWVYGwmg0qj3yZeOxz7IMsQSK2u1ROZINgw0RYok85Ak2M+bZuHFjI7lijBiNKis3onUMV978ijLyv61jsJp+8rsjDIboxNFC7WIoY9k8dIvPZSFDllf+rMpXVA1nUfuOhsNBLT1ClTFRVo5WlJUazrNK4pRFUWGpyQT5PSNMJiX50OpBLFtGmUxK5HUGRp63ZQxTtYMaKv+tBaZDQEAVEM+yvLkXw54cezSMNi5a6zqJPaJ9lzj6YOVMNc4aj5x7Blu6p8DiYuursqBy40Q0Kw3AZLIfS3kOoMB4vB+onZmLi4tJmstksoxh7aJYWloir3esjIg8w2h5hMo7OcGgjJXri9RUY53Vrow8zxtVZ+qUvfrW1wbc5+3gs3ExyAcYZABQOUjNn2dlrN3l/cvIKDZqFGOJoiybYLqCfKN1BqspkDOUraQm1aVmNLbkLNhsjlZOdzH8NBwOsbCw0ABkoIrV5YO8wWCWwp1lFY4C0DC04aSiKBN1wzhnQ517ZV77LMuwtLTUZIIYw49r1WbERob57EwCWhhrMBzUeW9tPYPBABZ5tPbUTbFSapLS3DtaUasYUxOMRTTviQPUlSNy2IRnjCE4iMxBbZM6PJDqErBB4TI5WXHGKBx+MiYxpp9MJhjXv804AFA5TdFVbWyNmuocDoe1qh820tEc0FkdeeCEQ+33amjuGcxSWRoGCxkCAoaDAfKQYWG4gEGWY5APmhCMPVAb7IWFhdYzHyMWFxcbyQZQkt9giICAybjCcXmWYzgYoizKxInZ9i1r/kII2LSpymaIZURRVCndjI0s69UiEMbAg0EdeI5ALIoqdbuyLSpHM6qBzrMMgzwHYpXuHYAq/QfAEUsbEWLEIOR1nDQixCobxSLgWf0M1kE+0eZ/eBgWBxtacBqRhFlCCCjKKv1mWMctDaAjAMv7l7G0tIQsr/xjrdMyfcghVIyV1wNYxlipm1DVZz4qS1tm9RPq2GEV6hkjosqyKMrWwrM6TQoBreoqyxIblsc44p79OHl5gCIgSTIEkJjJlXRr+22fsSyxdPtGYAiUoWyuC3GIpTsfjVBkiaSfheaewY657mwshdqNwK4Gh7qn+EhjW6EdHTS5UpVXIjYp2GkNZp2FtA2qJ6kXaJzDvcMYtJXq9xHUU+tPJdr0OnbMtPfVpvMIjXOMvvdd7D/1b5us21lo7hnsA0e/AmUskNUDVgL1TB8LhIdmMCdFNVsooMrCyAcDlLVaC6HKlw8hw6TOUACAPB80roXJaNKoNTMIJuMxskHezFqqMhlIOoRQRRgQmgxWkw779u2rguEwXGVWHRqQ36j+WsJa3v6+/ftrnLWALIRairYRhYjKwMhrVTnIB1jev4zTfvY0/Pzpj0rerRAzLH7gDGTLLVRYl2A1LW+4C9lCwKgoqtywPEcxKTApJiiyEpuOOKKx+BY2LdT5+QWykCOLGZABgXxSIQSMMW7cE6PRCBsWNlSZqRtavBeHtezK60yKOMEwH7YJibAA+KB2TWTINgbc12RqlBiF/U16kKlUzrjIQoYQMhRFiVBWbY+KMcK+Kkt1EguEcZvqEwJQxirlaDKujJBQJwBkRYb9xX7cnR8DbD05saRRBGBQNsmTq6G5Z7Cz73gBFvOlxgKyN918UPl9FfYpmvCKORXRSA/LwjCHa0BAdk+WWFVlWSIzrz0CBsNBE+6JMaIoi9aCNfeApeqUdUB+kDcDi1gxw2AwAGJs+pfVnvWyKCo/VghYHldT2mDuD4RGEluAOgCNyq0wXmg0qGGqMkY84OZjsXD3tiaEUd82wp1HIG7ZW2vb2VOm557BTj72dCwNjmhjczH2vIWMRwi+1IOVhIkSgBxTKFV/sbmXzQUWNapVbVulVNwWbaQcZ2B4ALspH1tcRe9Ke4d0manbqr72OwDEO7jumim33ovy4bvWJZhS8f99AeVSZf4HsqxirOdfN7jG3vIq5yrWEg5ogbwdj7CpYJGcpvUsojpPiwPYIcsqHFVPNyuKSixU0gbNZAqzCs3Ky7KQ+KOMwfI8ryzKsqxnlFcMU5ZFwshscSICMbT+PsvAqPx1lXu1qO+jmBTJBI/mZclj47hex2A1FaFEHFRv5niynHjzjbGyLDSZnI3or8Mt1W/K8xrUU99QAqFWmVmtZvKIItYzsocmMUuErGKuohijqMVSjBEl6tijSamsVT21bES0urOsSbeZxHFVIK/7USchslczZKgNmzZDtYwFRQAKjMtJFUut1W7IaiYfVDPUi9q90twnKIV6Rpp7BgN56Ztp8hQq6qSmoHWw1pcDSCVIk+tF6qrCMLKMAPnLGK+ZVTgYDFDGogHadp35y/g6DdFwYiN/GrFDt1GFWatmW6lXduKZ5vnnl9D6wPMFZqH5ZzC0cTUT7fyANAjMD5qpGZgQMCkmDZOUsfJ6m0VmTGaq075zVkJokvXSuZPcJ2YQZgB17la1EAgkfMj1GI7kXLEQsqQNe1Yspawec7vMmgfW3MuqSv84krzxDJQTYBu7qSg8gGUsa1xS4RFbQQf1uZJytFrwnGKrNjZZ5dBHxA7Dp5kNbX0sARmTWX0IdcpQjQ8tNtrcL0TS0fXKvDxdjlOu7frV+MHmn8FkUIBUzbCKsHN9sTaNI3IemUoXq5+ljw4OpzRrwJ3TaFQdcv1eAFqZAmhdC02qc0zrsH7ZXACus3Gd0D2tuymM6CGrqmweeEyxCdB9q5XpOCbZNpUygMfQ9sn1qdTi4zbgytxcX3J/5gZJb538V9xeW8Dio5w7xqR9XWcwImMkfXDDvHJiVjiqwiQW/I7oqgGPUVgqGOOoStHUHS7LzG7luY/e99b6zTr1gRynEZU7olHRIUdZlE0ske+O1xHj+2Qs18fY02juGczWanBVlOTGAzZ4WWIR8jl9k22QTU0C6Cx+ogNm1/dNnlAVzu2oivIkaNNu7LbfqGuEpA8eg/Pz4henD0J4NPcMBrQPfpJMNG3TYIwaTIN0ULg8v8l2XvGTa+kJYGfm0za8wfbUIZAmBnKfKgs3Nh5+ZQxOGefzzGw6z5PrOGQg/9JLL8WZZ56JI488EscddxzOP/983HzzzUmZ/fv3Y8eOHTjmmGNwxBFH4JnPfGZnucydO3fivPPOw8aNG3HcccfhoosuatJ/V0P2pqoLIsaIGIAyACWqT2QZCos3EkbjgecHrABb5woqiO8zMpgSIA5PuoZGYiZuCGIEV3UCtcMXQECyeIpORLG6+Z60n7POizzgDHbttddix44d+PznP4+rr74a4/EYT37yk3Hfffc1ZV7+8pfjwx/+MD7wgQ/g2muvxa233opnPOMZzfmiKHDeeedhNBrhc5/7HN773vfiiiuuwCWXXLL6DhGjeCoGqEI1WZY1boaS3mxVrZx2bZ98jFWwh808iWBl2Zrj+jnN267l78x4KdOnWNGswUgzwVkSteejazVyX2ZVkWu+EcMdd9yB4447Dtdeey0e//jHY/fu3XjAAx6A973vfXjWs54FAPjmN7+Jhz/84bjuuuvwmMc8Bh/96EfxtKc9DbfWyysBwOWXX46LL74Yd9xxR7NizjTas2cPtmzZgne/+0+wsU5F5ofGmKnvEXg4STGNd32fytJyqiaNwSycpcxndWmfPLXV9K1syyDwC4ZmIsq0/nmGSJZVSy9ccMEF2L17NzZv3uw+P+Ag+MF2794NANi6dSsA4Prrr8d4PMY555zTlDn55JNx4oknNpssXHfddTjttNOS5TLPPfdc7NmzBzfddJPbzvLyMvbs2ZP8AWjjfvLGqwrp+7MVdFTqmetAfVxchv1Hqk5TiZL2gQdccZK1bdRhqsr3W0MDnZJWzZsMIUvCU1wXh4LU/8XtzCqX1pTByrLEy172Mjz2sY/FqaeeCgDYtWsXFhYWcNRRRyVlt23bhl27djVlvE0Y7JxHl156KbZs2dL8nXDCCdUJebN1HqAHynXw1b3BDMGztPssO71Wy3Df7LkB7SJwJtXsOpO+/UZBQM1iiRpGRLOYnGXCcrvaP2uX8dis4L65p1WVXiXt2LEDX/va1/D+979/LZsBUG3EsHv37ubvlltuAVCHeQS79FltJi3YF6RWmoZs+iw+BfUeY/GMIq0PQCI5+6xUqzMESxFqJQ87aPV6+1OHMktU9XupWp6F1ozBLrjgAnzkIx/BJz/5yWSrkeOPPx6j0Qh33313Up43WTj++OPdTRjsnEeLi4vYvHlz8gegG4OriQExW4xa1pM+WobVWiIx0EoHTXFRS6+vXq4fSCe+etIGoVohKAQLvHeZ3a5lBvTaZePAq2MWOuAMFmPEBRdcgA9+8IP4xCc+gZNOOik5f/rpp2M4HOKaa65pjt18883YuXMnzj77bADA2Wefja9+9avJ1n1XX301Nm/ejFNOOWVV/SljiiH63n6TbhroTeqSRDt+0OqS4Gv4087xoiN8vtP/HldIn8SsuhOR5aFKfsxqcF/nr5WxQESVWMg+Qb4n6x9LOcZmq2GwA+5o3bFjB973vvfhr/7qr3DkkUc2mGnLli3N+vPPf/7zceGFF2Lr1q3YvHkzXvziF+Pss8/GYx7zGADAk5/8ZJxyyil47nOfize+8Y3YtWsXXv3qV2PHjh3udjErkaoGfUB9g+sNpqdWTXqwlcXMqI5V9p5rvaqaWLKqimRpxMcstcZzlNpscpsroKpT79m7dzN8ZqEDzmCXXXYZAOCJT3xicvw973kP/s2/+TcAgDe/+c3IsgzPfOYzsby8jHPPPRfvete7mrJ5nuMjH/kIXvSiF+Hss8/Gpk2b8LznPQ+ve93rfqQ+6eCz1FhJ1Zkky7J25UAlS132JJ8OHluEPKC8oqFex/2bFlrS+/WwFhsClkDI6s/a5onB6tJZjQS7325I+v9K5gf7k3dfjo0bNyZvoWZVAN0gNNBmX9h1Ki0QIzKbTBsjYkgTDnUw2JHKjKtMpC8DJ/xxP3mtfLvWzsVYuyyQ9iM2MdbWiNHUHiP29GuI7L777sNLXvKSQ+8HO9Sk74+CVf3kh6jLiXuTHaqBrNsI6SK8KhV08Ta1UJkpue+6JCa3wVZvB4g7Kj7Lqk0Y7H5UIurLxX3kLXIOuRV5fyEdLCN+sBwesXLew1RQnbRRRZWbetlqZFXVrCXmqEDPIODv0/Cb9dMLFXE/PFeDJ0U5HmnHbDub1dDcM5i6GTw/FjMRg2FVl0bNw6+lREQ1D7J0pI8nAVUyKNBWjONZi57DmF0ORVE0i69UVmWKy4ButgS3offg4cZZaO7TdVQNMgDmY1aGcRLQ3fVCgXhp19ezwD1r01PLnhRUhtPyRtN8aNb/au4kS9/urCTFlfqMNCVI25uF5p7BPDWj5/m7Dqy+rSwp+G1my8vIcxMwjvIiBp7FZ/iN1WzfQPcxMGppxm1zX/qeCd+bGhOz0NwzGPuD7MFNS/hjKaXM1jCDPWBjgLotL7dLMZZKEO+zyxx+gHmadFNVW5YlminDcv8K2j0DhRnf60sfzT2DAal7gLGLF3YB0qAuD0JZls2KgXZdlb1Q7XBbyLQ1/u6pRFvL1QP90wbfa8Ooz5hJpWvlB+N8fbvW8CG/ZF7W7LoVWRO/rQzyPTDrxdzsfOPCaIRXmsjI5bhOxTfcL83Q9aSCp3bVN6ftMRNqgmDTDwL6fdLK/thCVQNkJZp7BvNALJBKCLWqFJwnAx9968quZ8az37bQricpPQzUMDORSTrzrNs9cD95AWGVflzOZhDpvSp50lKt65XosGAwI0/SeOa+ls1DQLUrY7Wxqc0aYkZTZ6hda9svey4Iz9+l0tZLn+FYoy1G3IerNGbYMloaPmPidtUI6rxwK9DcM5gNFJvkRmwRWln+BOp0n2h4K5UYzCycmaDWIpACZ23TrET+bXWpGtYXxpY65/sz1auOUnuZiqJdnon7xvMKtC1+XvrcptHcMxi/2UqqruwYGwS8MrPHGM13pEzHDMO4yUhVl6pVK2Pqzr5zXSqBWMpNc6dYNoWnJvmFVIcwW+SzOlvn3opkXKTiHkiD2PbbqJE6od5RNqtmS9vgWD12fTEpEo+5nWe/lUoVbttzczBpPWzdMkOxpLT2OP/M9mPi1XVY8tp3u0bdPJ7q7aO5ZzBVifxd3QN9wWxjslCt0Nac0wENoWtJqjRSHNjH9F7/WV2qk1b7zPX3YcwY0/CXZk94QD6R7jPQYcFg6qrQgTfih2ykEg1lbHa8SFwUVeGOZLQ+eMbDLJaYMgkznKYT6cukTNxtr30GnFmhGJCl5jTI4dHcYzAeaPvNPh6mPmnnAe+O9KoKdupjhrLZ1H2D4/XVrvV8UPZdQ0daprkuojVYepiEDQvtgx1fT9ch0gfEx1bCPGothRCaWeB2fVdN9geztW7PavWkh8dY+mcr+LCRoE7Wsqwm3CIGF+SzJal99aTxLHRYMJj+AV21ZW+nB/oTQ6HHPI8xViDMaR9I1ZkdV6zk4TdmVM83paDck7Ytw6Uvluf/8ib1ei/CugSriSUMSxn+bYPfhy1SSdL1SWl9DITVH6YuBr3WzvFgTwPzRmwh2m9juOreMsQoYS95LjrLiKVnB3OuY7CKWCJxxihLA28yhmeJZVmGEhGTWFar8YhEBF2ng+OpX/tTNcvnNfBu5ElYIE3DNr9Zde8FgK77RBm8j4l+FOkFHAYMBqRvolFXfXSDwiyRmHEaSRJS73ak9gB0BlDVm9XD1quCeVV5nqq38+wGMQmYgvM05cb6rqv+WN+1bQ1HzUJz76YAuq4BzVDgh80M5y2FyeVjjNW+RSY1slTNmdRU7KV94vq88E7frB/v3jz1X92bv8aGtWPXG2PpIij2TCzYPquKnHsG0zdQwTSX0zI8eJ4BEGN0c8CMGHdpENw+bcA4B8vI+qO4TdWjzikoyzLZKbe+Q6Bn3VmFAtoutwn0T1T2aO5VJDOFPjBlIiuvzktVKc01VaH2Dykgb1VT2Zslywyi0+QYO/bhIi9Yz5LK82fp9Z6xwupTXTWq6qfR3EswxSt2zJM2HhBXxmRpFISpPJVjZYfDIQD0qjvPAZtuaTM9WK8SyD/fNSSsHDPOSkxkL8MsNPcMpg+pb1DsN5fTc56E6GtHj2vc01O3DMgZK3IIh69TRlBVutLz0HqUvBdBcdlKdFgwmFpuCoz1O9B90/uMAs9/5qldZQ61DLV9jQtq37WfHnPp91iHivha7+VSHGbgnw2hdSuypmkPgh/kNPUJ+PFIHXA97hkS3C6QOnkZD+miJJ61yHlbVheQ+sL4M8/ypA7+7rUFINn6kPu+zmA1qUXkpRYD/vzHPvWpeIXPe2qW61eG1HJ8rfVXlyz3ZgqxRanWb5Zl1cZY9d6SnsGg/fCgATPWej4Ykc6OAbqYx5u+pdLMU6e6+4WnavhaJm+ANbOW+824jK/hcJTXvq0JZntEei+F+rq0z/xSeZkofTT3bgoF2SpV2Fel0gboWqH2pzFOLqdxRwXz/MnkpW17kkR/Z1mWzBTy2qvCY7EDB7g9D+Ppi7daFbnmDPZHf/RHCCHgZS97WXPsYO70AfiiH+haQryhgqqtaWY7M5z95vqZMXVgmClZEikjc736XSUNM3/LUOmLwJLPM3rselXDfRi1j9aUwb70pS/hT/7kT/CzP/uzyfGDudOHqsJpFiWvie/hIw6R9Fmcs7gKVALYYOsAMpN5YSqrS4P33PcsVKpR5Q1HJrQv3kvgZbvOQmvGYPfeey+e85zn4E//9E9x9NFHN8d3796N//pf/yve9KY34Zd+6Zdw+umn4z3veQ8+97nP4fOf/zwA4OMf/zi+/vWv43/8j/+BRz7ykXjKU56C3//938c73/lOjEajVfWDH6KqNfVQ53nemX7GEibGmMzyYdyjSYgq8bSctaEqWwcuy7JEslobnvq1+tv+GTRA/Tfb4i99LyGXmxXkrxmD7dixA+edd16yowdwCHb6QFdiAGlYhcvZpz3EFMOUiaSxejy1a8yq0kjVnjGQXctt9lmWurhdfy5bm7bD9+rV6wF6vh99RrOqyTWxIt///vfjhhtuwJe+9KXOubXc6eO1r31t53gf/mILzX6z+vEkjapN/m1SRQeRB1+lpofr1MLzBlLjh949A6gXN7G+diMB1j9tW++ZJa3dwyFTkbfccgte+tKX4sorr8SGDRsOdPW91LfTh5EnFfrcFh5z9Dkbmbn4HLdr9WmG6rREQ+5rn7tA+93BdbFstvCLaO/JW9timgFjn8Zch9RNcf311+P222/Hz//8z2MwGGAwGODaa6/F2972NgwGA2zbtu2g7vQBpNhEiQeG8Yud64u56eCravPq0X6wleYZDbposEpSrU+ltXfPvFaGXqNM6z2jlRhS6YAz2JOe9CR89atfxY033tj8nXHGGXjOc57TfD+YO30oNpmW/MfMxC4DLxde1QxLBZZsfEzbULXMGI2vZ2ZVKaXHOmocXYnI13kv3bT6+PnMQgccgx155JHNzmpGmzZtwjHHHNMcP5g7fXB4hS05BuxAf3BbvfyzDrCen5Y4aN9DCJ3Yn5InbbKQI4TKFdFMTau384tAtWdk9B2katgwJPAMGruHwWA21jkkoaKDudOHSaBpJnjfmwx0F6XjQWBGVGay78yoimO0zrIsMR6PsWHDht66dcBjGVEg9d3xSxQQ3BdB8R8/B8OKnovCrp3VTXFY7PSxtLQEIMVCTOpF18H1pBLQVbF9WGnaZAlVkXq9Wp5sXLT1R5RFus4EGx8WMLe+2D2zpFIm7Hup7PvevXtn2ulj7oPdKrUYK3EZVZseUDdiSaGZqDxDqI8ZWcJ4Zfg7M4mR4p8sBMCkTQCAiJCh3jI5YjCsV6guuww6mUwaKc/zKK0dXt2a7++QuSnub8SMoiCaywDdWJsKd8/9wGqLrVB1W6h08tSW95vvQYG/1aPB9QjztLNV2LUYY0wXvltcXOyEw5iZldlmoblnMM+iM9LvzDDqie9Tk6xKNEjtqUrvOmbSvjLKzHzOtnip2kTTl/S+0ufhef/H43EHj/K9rK+T30ODwaCzt/Y01afHPWtTAbGV4/q9urkundThlfH6zOVDCABbftEwVj/W67OMlcH5PlVyzSrF5p7BDGcoSAX6Y3CqMgF/hzENanPqs5Gd83LZVX0asd9N+6uO2epaqifWDBPrkE7WnyFh13O9ykh8XFX9LDT3DOZZeKyOFG8oSGf1xxLAzrMa9VamsXJ9KdPaP8Y5fVLQ2q366YeVKuOgco61L4fvsZ+WLu49N49h+2juMRjguxPYv2UP2CaZWnYoX8PfPWuTJdS0lB8+zvVq3XpcpVhfGVadJTFt/SQ6kpzvna9VKcptcR9XorlnsD6speogxthsmczM56kwJX3Y6ki1+pkJuV51uk7rbx/jW5mEuREQy9aTP+2ZZM3m8V1L28Om6yqyJlu2kgfV+w2kHnX+7U208NSbGgZAv2vDzumA6eCztGL8lWRE1PWzJOXQVF+oq2mn9p0BqBfY68Y+9X7WVWRN3gYHSirNWMrYYGngWRlDsyRUnbBEVCzD0sKTnPqbjQsD+Upm4bJx4s0YqgwCuvesmwCg32dN1QEOAwnmSRtmAE0IBPxMgb7pXNyOSjJ1bzBu4+v6PPV2XAPP+rJEVCtfw6Rf2Uo/71kwVZZmQKD7CrnV0SYqWn3TnpFHcy/BjKaZ6QqYlVlsoHj1G2+gLeTCZdh69LIklPFUwikz+sF3AAGIsURcIUqh5C2bGWO1BXNVJ5LrGWLMQnMvwYy8t3eaFchYTDNW+RirUWuHy6nE1D5NU43cR2UqLs/tAgFZ1jVMvPab+0cAb7msID/G9gWxmOU6g9XkWUA86PapfipWh+xstGNqiXqqTxnFcBFjIlWrlg/GpC+H54nPQoZCmFzbt09l+lirQu+eQsiaqAAz9SFLOLy/kifBjBSTeQyoZa1OoOt59z7tu8YItWwfgFYLMZFcEYgZqp3hQteB6t1H8lyyygmrWLRydSBhqmnP0aO5x2Be2jEfB1J3hOIxs8R0hUIbwL5t+Ji8OYx6nvvH7XlBcwXdpsIUP3oWoBf/DGhjoyylqpetKmfbBvJLOAvNvQTzVAIPpieRlDgHynOqMmMplvLAdZ90S1wHaPOxtJ86ryDLs46EUdXt1d22XVYruIYA3tHXLMmyTO9vVuYCDgMGyxAQIhBac6j+6IJwIHVmWjlefI0H15iO32gPx6hqUaNAsR27KbROlXTVuRKmjKxsnucNnutjikT1Z7XnH9F8riib9tLr1q1Iplj5iCqsEpvUFiPNcvDeUp2hbeQZBsxsynjcHh9T1W3XsXr3wk9N2zGg2mhBjqPfP+f1M6J7jafWVyPB5h6D6ZvvJR4aea4GxR9cJ7sx1EBQ69VTVTrQfWDac0d4VpxJU3bMem2ry0VfKM6QVeznqfxpNP8MBqAEUCCiFEup7y1n777hIC/dxs570kklEBsS6qbgskbqPlHrslo1JyDPBk15vhf9Y1youDGVUrUkC9XMcLZKVdLPQnPPYMG2Qa7Vo8bmvBgi0L6tfXtv2zl96B7o7/tt3zV9WaWfxyQqyVTCeparYjsjxpb1Y6ot5Kyea9lK9lmnqxnNPYN1HJIkiTTHXC0s3YTAU5Nct3ecr7U/L5WH++CBe2UwJr6mr05mZDumfQDQ4LC2bT+daFaae5CfZzmy2gGZhazKeRKLkvGKWWD2WZZlbVVVIRWINFLJoz6iPuw1zXXRp75aZg/tYiYhJG4ENRL6+sOUAP6QVXMsQ+V8NV+Y9c22qJmV0eZegpkVmVW5wyjGk8Z1AZIMVdEuw8QYEWJEhtA8LGWatqm0LrVQudy0zAy9RsuE0P5FwZVqaHhZGiqNutKx8ocFVMzFRgenH81Cc89gDKJVUpnLwstQKMsSo9GoKo8098pTP/zpqR4rC6QLyCmGUiZf6b6qPz8NiNu0st7WffbdU7VAi9n6slyn0dwzGNAFyvqQvEkP+hcR6/26u8sy9YWC+nCLx0SamdGnQrleflkU/Hvn+/rELyAbAn2WtndPfXRYMBiQ+oiMVPLYG6qqLYaAGAKKsqzCJ0WJUEbkjtnfJx24zb7B6QP3Vf+yJrfeMFfbZjf7QxnVMwy0HT1nEYy+a2ehuQf5qiISxqnLGKA3YmvPrsuyeikkethl2Z1XqVmrfeDdkzTqN2OHaVm2IRzQstEhBIS8wkwe3mr67rTvqXS7RiGF9yxnoblnsL6HUeGq6jtLL5ZqfakzvHpNRJdhVAWyhOTB9bIS1IBo+lTt31yr6xrg28DXVqUXmvIkGDOftzyCSS6dfqf3MwutiYr8/ve/j3/9r/81jjnmGCwtLeG0007Dl7/85eZ8jBGXXHIJHvjAB2JpaQnnnHMO/v7v/z6p484778RznvMcbN68GUcddRSe//zn49577/2R+6QqoRJH1TkvpcfKatoM0PrHLBHPS/1hwGzfOeXa6rFPVrVsmDAZA2VZBsQAxIBYpu1nWUAZS5SxTIwTD8Tz87AUoWlSjV/WQ4bB7rrrLjz2sY/FcDjERz/6UXz961/Hf/kv/yVZK/+Nb3wj3va2t+Hyyy/HF77wBWzatAnnnnsu9u/f35R5znOeg5tuuglXX301PvKRj+DTn/40XvjCF/4/9a3zdmddEJuo0Bg74BtgoyAdNMU8/OdZbxpw7pMUVt6m4HFKDdfX3gOatGkvhUf7Z3Xwy8UMxuCfn+MsdMAXoHvlK1+Jz372s/jMZz7jno8xYvv27XjFK16B//gf/yOAanOGbdu24YorrsCzn/1sfOMb38App5yCL33pSzjjjDMAAFdddRWe+tSn4p/+6Z+wffv2FfthC9Bd9s53YOPGjU3b9pllGQr4qqxPBYQQEIuy8q1lWRV6quvgqMC0OlX9AWm+Gatrqw9AnZvVn2PWqN8k/RmNlFZDo88PxwwPwL2vGCP27duHl73sZSsuQHfAJdiHPvQhnHHGGfiX//Jf4rjjjsOjHvUo/Omf/mlz/rvf/S527dqVbMSwZcsWnHXWWclGDEcddVTDXABwzjnnIMsyfOELX3Db7duIgSVTx4KUOvrAN9eDEBCyDCXt7GkMy9Zb04bgOQ93TSaT5pjnk6s70/Spa/1F2DoUJrn0z4j9blyffef7tl3a2GWxWnl0wBnsO9/5Di677DL89E//ND72sY/hRS96EV7ykpfgve99L4B2IwVvowXeiOG4445Lzg8GA2zdunXqRgxbtmxp/k444QQAqfpgFRdjbKxCVRX26YLaAJR1oCZSpgH7kaatQ6+Jhh0Grqmz3FR9XJnLQH+1bJPMUkcb0GeMZeDejnuGhoF8ZSxN716JDjiDlWWJn//5n8frX/96POpRj8ILX/hCvOAFL8Dll19+oJtKqG8jBnsQ6qsKocpEV8ay7x7TAUgGyUtWtGldLLX6rEwrr8CZpVR7bde10L40rZVq9Vg5Dz+phPSYjF8aK+stP7oSHXAGe+ADH9hZy/7hD384du7cCaDdSMHbaIE3YuA18oFKjdx5550/8kYMCt7tzVfxr2WU2ThFR10OTDZA6tz18spUdSsGDCE0C8t1JB9ihzG9rAlNTeJrNEmxjyFZSnsJjx4dcAZ77GMfi5tvvjk59q1vfQsPfvCDAQAnnXQSjj/++GQjhj179uALX/hCshHD3Xffjeuvv74p84lPfAJlWeKss846IP2MMTaZEQB8BnQGm8vrdXatuSTYX+ZhGB5MtdpMjbG0BVJvf5ZldYZH+mce/xa+pcaBvhymPq1tz5/GKnI4HPb6CJUOuKP15S9/OX7hF34Br3/96/Hrv/7r+OIXv4h3v/vdePe73910+GUvexn+4A/+AD/90z+Nk046Ca95zWuwfft2nH/++QAqiffLv/zLjWodj8e44IIL8OxnP3smC5JJ1U9yDkAUj7310a6xQeYUGMVnRlxmOBw24N0zHuxaZSy1Qj1DgwebpacysIchWeKyitY+em3bsUM6s/vMM8/EBz/4QbzqVa/C6173Opx00kl4y1veguc85zlNmd/5nd/Bfffdhxe+8IW4++678bjHPQ5XXXVVsnnWlVdeiQsuuABPetKTkGXVpg1ve9vbVt0fz0pqjlfQxh0UK5MMKqnJWNabTYlrwa7nZaOm1c9lNNWGZwWhXhIg7VvZwXBWl7k+WL315dgz9a0krZhyfSOG2g92+bve2TAuA/7Kj5Um8WUh1FO1Kl6KsV61pjqNaLHHQHHIzDfflXnsmDdwrMLsmGK16ny17n31nzfX0VwWGYp6YwZTrn1uBjNKtM/TmDCEaiOGl770pQffD3Z/IxXx9mke8VD/M+kUyxJlUVYmPmOrklwDNTNafRrHBNBRu17ePQNlDrZzfDCdh1lHA0JXusbYOlir6wIGEpry3AssMa1tlqiKNfsYtY/mnsGArtnPas3OmyXFM4jsnF3HTGMqis+x1PHyxNTJqfMDeC6AEfd5Gtbifhj58dPulDVmMC/1SB3Hq6G5z6Zgsa+ORZ2eNk2l6QCWZdlkOPSB4z5rVJcD4EFmzKTSx4hVaJW3Y1Ks/lVWjuCANH6aZRkmkwmGwyGACidafdwfz5XB/Urbn05zz2A8eDpoap0Z6YP26gSQpOpolMBI87I8pvL65DlpfUYwS6W6vrB7NG6jZ2ASzBjLuz9bCFmfn92LzohaieZeRXpYwRtQVS9qGXrugxDQYRQeHLVgmdm0be8aIN1Jl88n6rJMVZnemzJ9eg+pBDbXimJLvpZfqJVo7iXYNCtOzzH1GQeqPipLoQ47yfUKlO24Ssg+iaH9sQVNuA8xVlalRgPsk4PsnsrVl8fa0GdodaiVuRLNvQTzwLEyjZFiC2YETwIAqHxpRYk8y+slwFtix6u235WGXXVp54wajFhGlEVsPPdqseo9cftsaNifvjw295EZS10YszLY3EswI8Y+nlRhJuQH6E0S8ZggVF+aa1Yy43XAvOPcZuLlD7GaIFtnbqhEU0bgYyrB+yIU7DYpiiLZ6nk11uTcM5hah15Q2twEal0aqPVyp6xuq3c0HiPUzlur167hsnyM2/cwHJdNX4B2eXPA37WNLWfuAzMOM5ad14ku1h+d0W2Gwko09wxmm5frW+dhMbageKAAdXiWdmGVeJhVi/CGjHbNBZrZ42UsK+ZDCqw1DmgJflYulWTilUcKtFWFW6hIrdg+Vc/MxP304IUaRNNo7jEYi3bFD/qAzRnp4RKjRE3GCuCXZdl+NgXRXD/IBx1p4tWtTJXgNKTqzs73ScM+PKY41DN0uB0um+d588KuM1hN+qD4gbE68N5MVhVqnvOnBpGBBo4lbfHsIU3yU1eHpvFY1EBxJA9+x7qsSd0jWq6PMTXvK4R0OdFZaO5VJIAOkDVG0jwte/A6V5CtzgRwZxlC9BktVhdUv8sSPEl3JYDMfbLfIXSZWNWr1l1J1nb325BljWT1gPo069bamGaxus9+plI/xmQMYW89h3q4DD9Yjcd5koPrUDxlx5AFZIM8mSCialrBOVMy4CEty59WT0dKh0ryVY7+2ATs9flotiu372V1cL9XosNKgnnSqs+6s9/8YBUkG9i28/ypbhHvPDO+Si1tp8n+CKHTDyuvzGrOX3VbKIZTlc04kyef9M0xmEZzz2D24DzwbG8uPzz1QRmp/6c5F3w1asSM7R3n39YO4PvSVPIZc6Q5XVxfJcUqi7I7hc2T0jqxQ/vDOHQWmnsG68v41AelD43xWR9jVIvkds17vt6wXp/zVaWnYqDmO1mRKu3KWADBjqfSscWD3Tb1fvoC2frMZrUggcMAg7GaYhHvuQsYi01TAS0DpPVxnYxdmLnUevT66lmRnH2rVrGVK4qiwVnqFlG1xjn59tmXC2ffB4NBZ/u/lWjuGQxIxbv6eIyUqTzcpGUD/e5Tq/bJ1qsHnLlvnqVWTPy1upiq875LgvvBbXrQQc/Zd89PuBLNPYOxKuTv9raqdegxWp/aAKqtarI64K2edWvPJoAYE2m2AmNBu1at3XyQJ9cgRFQCtA16I4YmYmD1eJLa2uSwEZBuhmWfKklNks1Kc4/BvLdTz6u60UAvSxa7puMyQBpuYaY1YtUFtLFBVXU8yG25NsOBJ9vGaqmdDjMZMYOwpOT4pQa6VYoyxLBdT9bdFEQ8aJ7XHfAfql07zVdFFQDoBsOtDru+z/PvGSIAuVhQze6OMVYbV5EVGctuXWxZ8r2txsXAz05z+metY+4ZjIGx55vyrEwlT+o1kgqoMyi6rgoOOLPkAvwcK26vWaO/aZQkYAgIWXfSiuImYzKd6NHH2N6zUwnbMT5WoLlnMDbBmWwgGJMxTrJrPXXF5yLvjx270ooZiK/VuYjT2gshoGSVFiMC+7ViGnPluky19W3lbH31nhFnw6p/cF2CESUSpwf48uB4MUr2LTUDQS+xWo96LZPXhz6Lti1XzQGw80VZUN39EQhuT1W95zDtczTzuVmlF3AYWJGe/8eOG6m0sWMRlI6DVhVR7R2J52VosHTR8kYcYOe+t32k1JmQvhjWX3aB2DGvLvVvsRU7jYH6tME0mnsGU8YB/FiaPdgGk2ShWWQuiKO0ffPbOszy5ARF9Wd5VqV9ejleKbOTCkXrIFV12teeGh/8EngSk18m7/ysKnLuGYzVW8e14GAJHpzMvNZOfbG2Gvkau86OaT4Vqyb2hSnTecCbyxRlkaorETiqApmBvb5q/exMVYnG+fmz0NxjMM9nxccZ/HpvOVBtaAoZ9MbnRUuZT6vPyrRqrOvMtHqVOfI8RzEp2wVPFF9RnNLDgtx+H55UpmaJxXlgZgzNurrO3Esw76EzqUoKoVphJ5EkpPYSHEb4ShmFpYZRozJt147YnaibYiigLCJiqS6GymtfFhGx8rM2A64M6lmoaiWrajVGUutTn9MsNPcMpoFjDYcw6Vr2Coa5DqMQWn+XZ536lM4P0G1sGn+XxC1jjElkwaRXH5Zjg4KlEEtHlVic3qSuFMV3s9ABZ7CiKPCa17wGJ510EpaWlvDQhz4Uv//7v98xmw/WTh8KrBV3eIwQQCqCcJZ5s1sJ0WVUdQUA6DCySgJVVc0AT9qdQJghtT4G/FyHkUkkbVuvZYa3T53mNs3F4dEBZ7A3vOENuOyyy/COd7wD3/jGN/CGN7wBb3zjG/H2t7+9KXMwd/rQB6/WEZdrjiWoHvUy4ZXLIoZ6GfMA1EtCdAbJSPFPY7HVC6GXsWhUZagbihFV6AfpJFeTQPzCaJCc701VoQbz+6S41WvXcVmr55DGIj/3uc/h6U9/Os477zwAwEMe8hD8z//5P/HFL34RQPXQ3/KWt+DVr341nv70pwMA/tt/+2/Ytm0b/vIv/7LZ6eOqq65Kdvp4+9vfjqc+9an44z/+41Wt0+o9TBbzNnAa8AV9Dwbk+Vx9XN9kbYuZxEIvVTlvPYqA2GPtsgGhfdVZ13ZvrPZUQuoCxXyOn4m6KFaTqgOsgQT7hV/4BVxzzTX41re+BQD4u7/7O/zN3/wNnvKUpwA4+Dt96FvKD8xb5MMsPC8LwX57ahDo7lprZOktyjihZlSWEJ4k9NpkdTkcDpPBt+M8TW4ymTT3663Dqliz717s+lnpgEuwV77yldizZw9OPvnkZqWWP/zDP2wWAV7LnT5e+9rXdo6HEJIZ2x7+YQnD6sdI8ZTnLVdQ7WI7OVZJiYgsr1JwstBdP0xVlAJu77cyi+7y5kEDlnBNu5CwWGyvn1WKHXAJ9r/+1//ClVdeife973244YYb8N73vhd//Md/3Gwls1bUt9PHNKcmD5gRqxgvrZjLq8Wl4RaTIryOQzfxMDbbwPDe2x5mUomiKpE3iWDSl8mzlJN1yOpkxhCqfP+IElWV3YkjK9EBl2AXXXQRXvnKV+LZz342AOC0007D9773PVx66aV43vOel+z08cAHPrC57rbbbsMjH/lIAD/6Th+Li4tT+6ZSRk3uRj3E2GAhxViMf3SgjTE881/Nej1v7SJhvv4Yol6rjGM4ywuV9T2bpk6SVMmnlJ2FDrgE27t3b+dhcm7Twd7pw3MVePgjxRr+9CzvzdVB1ZQZmyihUghInaCat+bhMc0I8fCf3hOrUSOWxJyr1of7mhcK/evo99EBl2C/8iu/gj/8wz/EiSeeiEc84hH427/9W7zpTW/Cv/t3/67p7MHc6YMdq0qqzjzwbb+5PF+v9Sgp8Aa6S5oDFcYMIWBSuy9CCIhlyyieK4TxoOJCXQqd79P6xFvVpA/GogVAnpOFXcYkYjALHXAGe/vb347XvOY1+A//4T/g9ttvx/bt2/Hv//2/xyWXXNKUOdg7fbAKVBXni/sq94rL2aeXeqxvs9atCX4AOmpLQ0b8aXVyxgaX0UB2CAHj8bjpL0u3vkxe7Y/hsqIEBvWEk0hAf1ZH69zv9PGOt70VS0tLALrBbH74yQyjPEOJVHXqw7drvSlm5l9jCdMnDZVJU+YKvfn2PMDKHGa992WuekYCU9qnyvFsFu8gryzyWXe8nf9siiwDjAkotBPyDGWMKFE7UutF5GKMTbAbaH0+GvSdTCYNGGemiTE2qwEqLpqmalWiVJgnVXuGmVTlMX7il8LOWR+ZMT1jh9tq6kfloSjLKu7Ju7LNQnPPYGW9ugxQh2EIvOd5DoQqmc8wl1qA6j/jlBuVXDrIKtU8NdlndfJ3W/lwMBh0dgHxvnvedlX1nitDsVnTL3HnqEEwjeY+m8ImRACtZdQX8NZtjPm7Wov2nesxhmTDIoSurw3oYi5Vx4ECotbfNNTU764wZuy4X8qyo171/vpijZ66n4XmnsGCs0k6kEoUBcrMGGqdcQqNlyWr081UZVl79sngnctHdCWjtcnXqgfeyjBw9ySWev/5fvl59LkuZqW5V5G2tYo9SA+DAL6/zLM6+0C5qh691rNeuU/MtG29PkYCurPIp/XHU9dWlvuh7XtSjNuYheaewYCuauAHC3SZSh+2qhUr55XpY1T7ZEmqzMBMWIF8fyDZVeK5F7hdL7XZ62efWrR62J+3Gpp7FcmLnKiD05NGiofYGtRyrFb44au6sX7MArTpV0elGyk+1IRDZVxujw2AvpdAyTNOZsVhc89gcFb2A/rFfZ/156Uv91lujIGU8ZSsbmXqWAfAk0RF+mMPfgihN4WGGdAkuTE7e+WT5xGAiBIIlQ+M8SU/h1lo7lUkD4gO0DRppupAk/xYRfLCbWoY6LWqzkyNsbSzOsoiQvfptk+uy9uknfvK/bR21XeWWNKB8Wpr0aqBMQvNvwRDNxNT8YeHjaYZAFzWsxr5+r4sCh0kT11519i9mCvEw48evrJPk1zaNl9rL0wIoZkSZ5KLIx+z0NwzWInYy0iAox742p6sTlWXzeDEakG6ENt0H8Z1GhP1Qjl9yYNevxWXsZfdk8QeVGDrtWFEWkyvmj9QoiyLJgFxXYIJaaoKz7Cxt1MxDA+w97ayiyAxAmJEnrV12Qafdo2VV9Dfx/TcT/5t9fB9acIjGyBMnqXcvmTp/Tf4LaZtzWpNHhYYTB2Z9umpKB1IZjKLP/J5lhB5Xu0ZWRRFtd0e/Lfcw1KKEe08xzW1DsVYTMo4noGiBoPVayv3cP1N2nXozmWYRnPPYEDX680ebvtt1Dcbh6/pwz1l0S6KUgrjKUDmCbRe/a0aTdWkSrM+/5v2WxlKpVo7y6id4RSAOpMiR4xlM8M9xjTSMI0OCwZja40fNjAdUCuj2aD3GQAxtB744EhHHdQ+r3nzPUQUTZkMWfBV9Uq+K5ay/MlSLmX4+sWzOmJZB9yzKiMla/c/WonmHoMpiFfQPi3xj0E5M6WnWqelr7A/jJnJm+2jaqm15tL2pqk+7jOX4XI8kZefk7pZvARLSwGaheaewdg0N/IYRiWWDphab55n3a7twz9a1vqix+27GQiVSvJ9cWp1egvZ8T2pBNMXhPEel+m6P9YlGAB0How3wPZQWcL0+bGMgTTQ3MeQ6mpQaWl/ntFRbTRfoaEoDKCr6Vh906SsSnNPLatETSMGGRBDuzrQDDT3DKbWmUovJX7whts0d4sZ1sN0yqRGymBWXjcTbcsbg1ZA29rK8xzD4bA3Jqh5YNxPz/r07klfMttMwjDmIZv0cX8jz/LSwfQGF0jjfLrTa2M5kk9LLUGWHKo2uV0r05WC/pQybkvvczXZHfadXz7NA+Pnx1borBhs7hnMVBC/wSqlWK3E2ObU28Pk6zmd2JgPSIPibG2qUeExtVqnTf9i1/jwVB/Xp+dSyV1L4pAlqUAs2Twnb8N0WTXbqixLZPm6BGuIRb2nLq2MnecZOaoK1Lw3NdpXv2I8K2fXA20gmmdzx1jhHFVpfUaB56rQlwqs9kIAkE5pUybT54YI0AyGmZ79YcFgQL+n3s6pejSGMO89W3Z2rQ48/2ZJYINlxzxfmmcU2HwCz5XRd713rJWsaZ90eQJ96Zj5qpfCD2VNo8OGwYAWu2jAdjKZuLFIIJUCfYPYl55j5GVUdM3+LjgvJv5kXO2TYkyVbo1kbQLYQECEXaIvn/XfC8YHW7x4RjfFYcNgfcBWGUSZhqWFJ/1YKhl5E1+nWaKaD2bH3QF28No0aZJKMjpWM1iMsZoYU6ZteC8YOx3KcjYJNvduCqD79vNx/ePyfWQMpQ7ZRvJInJHBP/8Z0/GySypNFK+ZZNFjXh+9utp77L48ChXsPu24viSz0NwzGA+aJumpC0AlATOIfao60/LKxJ6RoFLI729l9bHbgNOMWM0ro/B3819ZwL0B8Kj8a5W1Ot2d00q8/vkEfTT3DMahDo+B1IuuoRF2O3juBvUHsUSz+vS41p24Nqo9dCtvuUz80IxUzaTlMka2fOdkMkGVY28rKqJaKqEE2HGqjBMyIKLK6rB9KoFDuLrO/ZHsrfVmRfNvHmjPS67qRKVRn0HAZbgNAEnQOcuyRpoAbZoPq15mpA4zUH+8FKEQstYviNCk5rBE0pTogEp6tdIPnejG1Gc/U6kfY1JXhA48/7ELQXGTEdfBVqn91jbtU1UaH9cYoeZysXfe/qwuXtiE6/YWOAZSo0YNDTuWrBtG/THXF0cmVqJVM9inP/1p/Mqv/Aq2b9+OEAL+8i//Mjkf44HZZOErX/kK/sW/+BfYsGEDTjjhBLzxjW9cbVcbUsco91UdjTygisGsDF/P9at65etZreksIJZMLL1s46kQ0h1KWE3ZAseq6lWaVlKHsVfWYVgOvtvvZGeUeimnkAFZvkYY7L777sPP/dzP4Z3vfKd7/kBssrBnzx48+clPxoMf/GBcf/31+M//+T/j937v9/Dud797td3tMI9KMtvNwrO6+HpbTMSWA9fsC6CVMGwdch02UFZGGSbGVkKamvMwj9c/oFVdLFGTYHasXRUxTcsx0jQkfuGsX+PxaG1Tpp/ylKc0a94rxXhgNlm48sorMRqN8Gd/9mdYWFjAIx7xCNx4441405vetOrdPniwPAaaRdRbcDfG2EiMaVaU5m15gLjvek+Nanm91u7NluFkY4KZuk+6MdPrs7GfVs7W5J+VDigGO1CbLFx33XV4/OMfj4WFhabMueeei5tvvhl33XWX2/a0jRiAbloK0AX7Vl4n0vKAsTrkelgVsdpRjKc4MAnticuB29eEQHVPeGVRTzMrSp4H2ebTa7+s/hSLVurUvlfrtJY0/2A6HVAGO1CbLOzatcutg9tQuvTSS7Fly5bm74QTTgDQrxrtHJPiEKCbrmLlvPAP18nt9LkUYoz1TrZZrR79rAlWXR5jef695t4tf752UVTbMddsJteo+6SpKwL1SgawuQF5Ppvymxsrsm8jBmYQz2qy316qsx0fj8cAusyquWFcn+Iro85v6iNbh8zQ3Dern3PQuE2WtBEpo1r7GpYC0HkeVlZVtUnPQ+Km4E0WmG677bbm3CybLBx//PFuHdyG0uLiIjZv3pz8ATTYQGNmKyYB0tVvjNQl4JFKRGZitsjsvNVrZYtSfVVpZgP3g/uja8ay9GlcEaROraxZppFiicqkTHmeN178QOGlvuehdEAZ7EBtsnD22Wfj05/+dCM5AODqq6/Gwx72MBx99NGr6lOIQCgjQgRiUVTfy4iMYVBkR2Kq2oD+OJ0ylKdCGc/wb5VIPHDKXJ4UatoLaFwH1XqzZfMZkUpdq6+qoz1nxoEviSugH7KUuWYF+qtmsHvvvRc33ngjbrzxRgAVsL/xxhuxc+dOhNBusvChD30IX/3qV/Fbv/VbvZssfPGLX8RnP/vZziYLv/mbv4mFhQU8//nPx0033YQ///M/x1vf+lZceOGFq+1u8yABZ5pYJ9+pPk7qhh8mg3z7zd8V63nA2fLJmskUIQ3TqNvDiH1diVSkmKXivxC662s02R+xGyYzN0dy34GeB1qGX7OU6S9/+cv4xV/8xea3Dfrznvc8XHHFFQdkk4UtW7bg4x//OHbs2IHTTz8dxx57LC655JIfaUPSsodJqofXj5s8C00tUZZ67H/qDnQbGejk3kfAcu/V4rU62n7E2qpLVVSMFZA3P526JBQ3VnVmnc3k7buFmWKscsiy3ALkq1t8DsD8b8Twlje/CUvE3EWsfQIO8PdUQHcwu34pO671KbOqmq0kSo5iUnSYi6+xbNKyrJZkr2Z4UxnEasOGrFq+oMJKqDdSpb6XFTNXPi//ZeIXyfqb59Ze2TD4fffdh4suumh9I4bkDQZqkY8kH5PVpFpNKsnsDQe6W7ooeXUZwzQgnV5vL67YMEA1xg0DmJsgwXIlM3lt2CQSKkOWDep7baXotI0jqvYs+9WYbA0x2I8jtQ+tHWAO11gZT8IAqVpQtamYy8qpH81Tl3UtLsgHUkwEkKWYZ4mhoFKzvSd6BmXsYDi7bjQaJcFufWn4Gl7OYBaaewkWm38V5VnemNtwVKGqRAbeygQKwnlANHuCsU3aRjc9m7MnUjxnKrCSKtxvK89UpeXU/cktx6xNlWbg72ExfQbK0LPQ/EuwEIAsqwF9QIgR5aQAyoiMgtFe/FAZxMoqYGaGqppMLUFmHFW9Melq169lFMsaZ9Vef88AAfzFWxq/WxYat4b5tric0SxhqVlp/iVYYrHF2mFUDzDSQeKJGuPxOHFrsGqz71a+qU+kGw8MM8E0E1/xHjNnX/q1p5ar892c/lYyheSedYKKqvVU9c7uyT8sGKxVb7UbIQtVRidJJsUx5nwEugOneIrLdTaSgrhGkEoqs+YU/2m/PAZgJm6YL6D10ofUb5dYpsK06t9Ty5JpNZJs7hkMoETALNRuCjSmfPW9+yD7rEjNLlXG8N5slkI8/zLUnSijv4YEkzfIXalUa8Cs7kfs1tmq3vYB9Bkwfe1o3tg0mnsMxkDWOw6063DZw+fsU39wuuk6So3FR5JHGbIP23EdfffD5dUQ8aQfg3mgxnRO2RBC8zxUqqkqnYXmnsGAdKA07SXG2My8MbIsV2YQw0183FwFHGBWScRMyW02zCFLUaoLwFOfLEEUH6FHpbJh4lmp/OIMh8OkDjZQvBdsGs29ivQGyPw53gRZI5YMfaDdM+mtzq5ZH5oZOq3BUakpswpVErEELcuywYVcrzFp5VqtduaIEY0BEwI9g3oqnM0Osvtkn6CuFtSHw2aluWcwIM2WMOIlyT28odeppcbXMdN5geuKoazSdvBbz7tvheqgMtMxg1f8G6r6UPFuGcsqdGTGRQQsM7XqX3/MlNtjYuaeleZeRfYNmDKV56Ni9aYMk3rZ/bQcoHZJOJCFc8KYNMOB23b9aKT6TFI2KpQkEPu9uC1+FnyM2+Uys4L75j5XVfrHkPqkkzKbZkUwk2lYhv88HGPUqJiQ4i+gG35iVWzXevfB9bYvBlB7T2GxQgXw1X0UGI1HmBSTTn3cToyxXYC48fyXnTTrWWjuVaRKFJYyfJzLaxkF6XbMGIwdpyoVQmixl9c3TfNRXNfXH7ZMq1naJRACAq2lH8lNEUIAMmAhrwB8UVa7kXTVrZNZa4ZIbDeYmBWTzb0E48CumvZAd00uZUg75kk8IHVxcNlkoEKqYrqSxQ+maz/seq8vrLraNnwXiH23F4P7r20HKo9VMJbRYSHBdPD5nGdBqodcTXTGYfZbU32sfGVVZg0OU+nA7aha1ixbIF0ayurxJKgnCVkaZiEg1PfWN29Tr60wXetTm4XmnsHUtcDHgW5YxIj9XEAbBlKV5jlPuxImIJZwB5MNEMZVyvyauaHtKlBvfXOpH07nCvQ5TtUHpi/Xuop0iJlGsQeQhof4ofMMHsNcGrhmTASkKrcoWscmW6xqFdqnugJUxauhYW2xA9UAOluZzfXoTpFjqWTS2WN2u9/1rWSE7KHpYAE+7uHBt3Up+HqgZSbPPVHFAlOJpsygkomlmZLOGFdGA9oIBJNiT6AK9rPQUvXL98b18LOZ1R92WDCYh7tM9AOpGmXJZQ+TNxVVa8ubyFGVNe99uya9J4FUPWlOvn3XrZutPu+znbGUtTOyLREMAWXRzaBlvJnneRI+Uym3bkUSsZXGD9IDqh5G043UWeooBktAMdVj7bM6ZWnDakxVlbWn+2yzJLPfbB2m7QEWquIcOK2HmVsTABhaqOSdRnPPYJ71xwPVd87DNfbnLWGpb3YQd4RiPVs7tS+blPuvUs6sU5aIxhzqie/LZbO27Hp2dXAQX8nKrge7a/Icn3ac13fgh1ltvpkuuMtvuB1nXOepOsBP5fECyZ7LpM/BqupTy/M9qqRTqeclJHqGAz+7dQkm5EkxXosikTwCmnnQWUq5Hnuup26br/GMCbUeleE9rMOD61mTeh/MqMkelI6Ro31SC1Nf1JVo7iWY96YD/urP/EDtnH2qFPPwGlMEXEa08qw2PYnmuSq89hRXesCf79+TPB728xhIYcEsdFgwmJJ63VW6qcpTRulzTjIzBz2GNmXHU9eK09R4UAbi6+x7UwapdNJ67b75vEo0VqOcbOlhwml0WKhIfbgGkD01pBJMLTc9boNnma5N+Y7EifWKN+mCK2z5aT+1b30pRenNVm2FDM1fsz5+lmaGtH1Lv1t/7M9rf93RSsQmNqtGHlTNHvUwDLsTrA77tMWB/QFTxmiv8VSyxj41pdvKcl9ayxKdvraM31qA3FdPcqt/j2lW/AUcBgzGDwxAM/WdVY7HFOqCMPLwmRoLqiJZmlm6sqpgD0wrE3H7OjsphHqqHbrSrY05VozLiwUbs/Xda+e+VsFcwGHAYDZoKqnsGEsuK89qSyWW5zpoLcV61RpUK5U09ZcRiHV4JspABTRJfQjd2CGrZQ0D6T00yYf1X1m3m4W8Dran6tjb+5KZUyW0GkSz0NyDfMBPKmT11OeXsu8spRS3JdIihiaJj3fBVRVkYLlSVwUs4zXP82ZbPQ/kK3bkfnj3mmd5px98fzZ7iK81Vcu/WeJ7VvQ0OqA7fYzHY1x88cU47bTTsGnTJmzfvh2/9Vu/hVtvvTWp42Du9MGqQJkISBlg2h48/EB1sFjVeNYYMyOrJFWtmqWhFt5KcUCVPnYNS17FVV7kIMuyJpSlL5SuErkSHdCdPvbu3YsbbrgBr3nNa3DDDTfgL/7iL3DzzTfjV3/1V5Nyh2KnDy8TlAeLQ0EKvHWgmRFShiKrcpBXG6eHCuSHAGR5hnxgq/uUKGNZLV9AW7wY8cCqFNW4oIePWOLYdy+eyfFVDhdZ20r6oq5EB3Snjy1btuDqq69Ojr3jHe/Aox/9aOzcuRMnnnjiQd/pA2j9WApYGWMYqTpVbGL1MTUxPK6nLOvt79hRa1sa10xRVvMYs6yeixjaWCDP27Q2FZNZ23meJ0utM/Oz+jc168Uc1Yr0pJ72YRZac5C/e/duhBBw1FFHATj4O30oIOUBsPN8jslTRzoIiaQBWYKO9GDMF0LlOxvQeqgesPfANA92URRYXl52XxajJn1HJJSqb71PXgCG1X5fOx6tKYPt378fF198Mf7Vv/pXzTqeB3unDwDNYHoSyJNodtyTWnpMc+ABSzas8tcrxomJF5zVG0sQjo/2SUzdqY3Veh9pXZ70VjXsWdheJu5KtGYMNh6P8eu//uuIMeKyyy5bq2Ya6tvpgyUOkG67wnjGSMEvD4SqEa3TqKo3Ngl/iwuLCbhOMJ3chzlCdWCtXu1L217qSFZJs5LxooymWGslbNZHa+KmMOb63ve+h0984hPJKsRrudPH4uJi57g9OH3zWfoo03iDx7iFH/ZgMOjk5StuM1eEJz0CWkzGmEedqxqaKcuyWbwXaN0aXgIkv0x6v9onvk/+XFhYSHDsIUvXMeb6+7//e/zf//t/ccwxxyTnD/pOH1NwlJ7jh67MqNLHJN9oNGqvp3VTOdWnqNOuPSdt6MmqtWINVqvnBQyHQwwGg4a5rLzVD6QWKOMu7jtDA7tmWn6Y3acHJ6bRqhls2k4f4/EYz3rWs/DlL38ZV155JYqiwK5du7Br166mgwd7pw9+m5VBPJMd6AJ5/jQ/FqsO2/snsJRCFWDmzAZ16FbHrVy1BUwZC5T1NH3UyxeXZdEsUsftszo1BjTGZwZiC9J8Wx7eZOnMz4NdGNOMCY8O6E4fv/d7v4cPfehDAIBHPvKRyXWf/OQn8cQnPhHAwd3pg10TKrn4t+I0D9Tb283Sg6WVbXQAoF6j3nxgwY64GE5VsDGqefgrX0eKoxQjGfOoKmSJMxwOOxkZ9pfneRM64nrbPqVrhM2Kw1bNYE984hOncu8snL1161a8733vm1rmZ3/2Z/GZz3xmtd3r7Y++temA+lmq6jLQAHk3r4z8RbYRAlLVa58ek3n9bNWR30cjfSHUIgTaFBvGe/ybQ1j64in+mpXB5j7YHWMatGaG0TcTaB2X6iLwVKsNome+B6QSQgeLc9OsXS3D6o2NjT7cyN9NFfZl1KpRoMTHp2WTrERzz2AsnbwHZQzFTGOBcHVKKqkqyvLUQaqq2JiGN2Swc+zq0L4CFcMqsyvTqLSyfvBsbG7Hi0v2vUgK7tclWE1FkWIVD7x7AWiVTkC/WrLvsezf/QNoJYGlvrB3n+dIMgMZaJ/I7CXFj2rdap9NWqmkNIbn9uw6Y0CWsn1JiH009+k6Ifh56PwJtFkC+qZ6KkjVbTOIdd69YTBbOkAlAUtPO2fb8HGb1q+KObq4jbGUhpkYRynWmvayGXn3p8bOLDT3DAZ0GcvzA1k5bxCV1Ipi0F/Vn66BwQOrUsh+s5rWfsdYZ1tQ+4zPjHQTCGUID5wzkzPjMUblc1mWJT63lWjuGcwGg4EykEo1D7gqMGfyGEItN68OBtWaqWB1aBuN5ZdVa65yP9Up2qe2lEm8fmqmhfbLnh374GahucdgQJu/bgCX8QrQ3cVVGQLol1rKJH2knvI+dcwDr5NSmFRdqzWs5fj+Oc5qqtCTVmykaOhqVjosGIzDNJ7kAroPrVqVJmAyLqoFQ2Ll7DSHqef01CREZhj+rW0mhkER67aqXHrEesGSmDIl+6Q058vDVHaeXzLFgyxd9UVUY2JWkH9YMBhjDx18I88Ebx+olUnrDSEk09U8XKdtKuZKJU/oAH9u1/PB2XduS31YzEjeGmLs0mBJpsmJq5FcRocFgwGtOgC6GQOshjhrQZnSyAZJnaFGnvXFEkIzHux8oHaZEbgexU7j8bjDTPzd7tHbmlCZHqiyUnhXW6/u1dDcg/yybPd1ZEaqBhm12kvB7GQyQZ4NOgyWZRkiShRFmXj8+1SGpx7V12SfTR08rS3UfXVUn/3ZpFx+gaxOTmZUaafWLAfKOWJg3/kZrobR5p7BQkgfZvLGRnrIWTvlLM/zehJGF0NV68SnaskD/3bcU2MeVde1Iaaqzog8J2kbp/uujMqy2tDKMJdnAOhLp2uvem4IzxBaieaewYA0JMJWUQCFdooySQoEUovOymW1ZMmyDKPRqMmsUAuQr+G3XtWcUXW8mgRizGWrEbbb0XSXmmIVZtLGSzq08ka8sRZDB7V0TXopyJ+V5p7B7Fl4pngsy1ZDhrZwCFmTPJgOUFVO3R0AoPn0di0DapVsymzVrKJWLZeRZxX564Wp2vVWvfakHj8PrlOtY2uTpeC6m4LI1JmCY6AK7eR5Vq1Ck4SUdEMqSwhM3RvslLR6eYA8ScLXdjJcsy5e43PtPXWzUa199WFxm3aNl3Dohan4nngm/GqY7LCQYL2DJtikGQiENtmvOtDMWdSHrEwFdFfj4cGz32Ypct+suUbC1EtEe9iH67V7YHXM7au/S5mLjQEmvk8zaHSCy0o09wxm5DkLFZsxQ5UF5V7Ry8rr1XPdQNcys7IqqXq94sRkdTeAmjmKSYHBYJCoKXbsamqRF9S2754k009OPrTj+sxmocNCRZoK8HxBQDe7tSxZqsTEorQHz/4yzsQw6lugjQfHGKGRMpnuwJFV2CuGhGGtr1ZHn7XqSSRul/e81Lgmg3+WkHx8FjpsJJhag/zJzFEURbPVSiMpYtm5rrFEQ+gAa/YreWCe60j71qrcJpgurgnz7ivuUsZiKabSyK5X6cTPwbNCVQXPQnPPYDGmKomzSRWLJIxREkar1+9iD73mS6mV1Sc9vIFJ8WHotJO4Vsh1ALTzMjvulFpiq0pVg4SP2XMaDodJkiG7MZh5Z6G5ZzAdT1UF/J3VUATjj3b/a6BNs67q784O1wHRNuy6aqBITcfYkSDaTyDdeF59VCpd+LfnZuAd5Kye8XicMDU7Zfv61Edzz2C28bqqKgbBnZBK7dRsBiTrqjgeAP4NTPey6zGzTrWfgB8z5bo9taiSzMqw1OYpbgASScd1eLlzk8kkWTdsJZp7BjP8ZOQNkgZyI1Atv0QMw9dxDhWfZ2pcDY4zU6UTL9vEfVSJ5Kk6vi/+3hfvBNLAt8IE7b9anRYBmBWDzb0VaWtvAamK4IfWVZuxCRvJ3lFi5am6KxP1pYycMlZtDFAdDLw9VcnZGHw//ffe3WqZ67E62DpVrKjuFbuvdTeFUWwdhV7YxgaJJ6VWn6i890jTVdhSZFJmY6PB2muuRRVYt4WBPbWnUsv6yn3X++BjfI3dv9XLjGLrXrCk1T4zI6/GRQEcBiqyWtuhG1Oz3/bJbzpLJCPDLZptwIzGKsXti6kbVIKxEyoK5Coh9ei1xUzJQL8PG+n99KlDvUZdGKvd7WPuGYwlT/WX4hGgHSSgm+3AA2HzGRWzqfnPKo0lSNOucRi6wWp2lVgdVo77yziIGZ8ZQrGjJjxyvfrJZVRdryb5cO4ZLJb0tkW0+e2w9JiuZAP80JIHuKe5AZgpUikUOtKLDQdeAacvDKVM4lm42g+WzMp8bd/S61Vth9Bdq2wazT8GA2dPtOnOPACKnxILT2J8nnvAskq9QWWqHKTmuE0ZmjESW3tMyjjePXqhpD5G9JjHrmfn7XA47M2MXYnmXoKB3nZN/TV1CbQPlFOF9WHqG2/E2w8baSinVXnB7IYOo6g6nNauSjcrMxqNOss4tY8ibS8JSTntcCyS2+XPlWjVEmzaRgxKv/3bv40QAt7ylrckxw/uRgw8UBXonxQTlDH1TvMbyikpMUZkoUqhLouyMxjGQLYAnEoZ9SXFMjYLzGVZ10fFdbbB967lZipVd3nzmMuTWnmeN2nVfM7K80YMCgdWg8FWzWDTNmJg+uAHP4jPf/7zzaqFTAdzIwa1BLMsIMt8LOHFGmOM9eqCGbIsRxa6D9ekiaeWFPdU6dZVHxCQRAl4gwfGgOqj4noVQ3kMrgZIjO3ucOoI9rCX9Ydx4ZqB/GkbMRh9//vfx4tf/GJ87GMfw3nnnZecO9gbMQT4cxWN+o63W+jV4ZXSgr++RaUBdB4EHkCdet9YldznkPZ5mjryrEuWOOzysLo9FayWrDGShw1nZS5gDUB+WZZ47nOfi4suugiPeMQjOucP9kYMTIyteDB0afMUqMc6fSck6lbNdR0glTbeNdyeSRr7U4zV9gfJd2MiD0dpvFUtSGb6aZhTXRaz4i9gDRjsDW94AwaDAV7ykpe45w/6Rgwi7nUQWZoASAahOVbn44esDR2xlFGfFbsRVHXa+abuMnUXMMN7TGplGXvxRNk+TzszlK5FptY0v2xczp7LrIFu4AAz2PXXX4+3vvWtuOKKK1YlRg8E9W3EAHRVDtDd1RbwY4b60PUYMxMTM66qraRsSK9RUheDYi797qXVqERTfx0Dd8VeXIdK1lnogDLYZz7zGdx+++048cQTm7Xcv/e97+EVr3gFHvKQhwBY240YNm/enPwBAER69eVu8UNm1dE+7O6cxKr6rvVnUsja5CBzi3eqqEJG4N5zK/Qxi+6nba4SVXVq+TETqQHEn6r+WV0eMgz23Oc+F1/5yleadfRvvPFGbN++HRdddBE+9rGPATj4GzGUseu1VksL6KqvVHVWvivL1VdrsQkVxVAtZV7HyBXTGBNVO+DWUQWExB3AKoilqddn7qfiJE/1awau+t3KsnQ3KfUk2qy0aivy3nvvxT/8wz80v20jhq1bt+LEE0/s7OwxHA5x/PHH42EPexiAdCOGyy+/HOPx2N2I4bWvfS2e//zn4+KLL8bXvvY1vPWtb8Wb3/zm1XY3kTSaHmz4xTP3mbIsa5iClw5QH5fpuxBCvQ9k6Q7ycDjEZNKu1dUnKTjArrjIMwT4mj7VqvVwv+y5aDlP/a+Zm2LaRgxXXHHFTHUczI0YgK41xIyhMUf18VSSCYANPspOuXbANLDcxWumPj2/kicpuBzX06R2CxPwDPOm/0DH0rS6+M/LBvHA/mosyQO+EYPSP/7jP3aOHeyNGPRtU+YA/AyLxiqLpDZDBl7DQiVQwwglRwdgYQRUSw/4uVstPvNXQdTkSMAPL3nSy8vA1cxYT5qq5XjI3RT3N7IVc9S81re3D0zHGJucsrKst0CWt96zvkyi2ZoS5kzNJcPWk3D2W3EZ4y1W7coUdj2ABsfadDfFcmwAcN/tfpnJV8tcwGHAYED3TTY/kIaGvIEKoYLiDSNRWjQzlaYnW526UbxmzvK1nhXIu86aBJpMJsm+Qr66bmc/mRHB2ExVNL80rH69l241ywfMfzYF/GAy0L7VdlxVkuWOAW0SYJZVKpIzImIVYkSJ7mQQI8V9fI4HVJ2Y7Irg3HlN5TGDhX1d1l9eI0yv8axSoDvTyurlAPssNPcMZm4KJrXEeGBjjLV33UC6ZpSGZmmn6nv1rTCgjhTf2ABz26pqjCm9Add06BBCw0geE1hfVbVZvd5m89NUIGNUlaSz0NwzWEYM0udHMtO+vQjERPUhMeMVXPOAAXDdH3w9GwncF8/Q4POMjfQ6D79xv5mRtA1PAtp9MgxQh+xKdFhgMKCbE8XHbVYNP1R+W1Wl9ZnxfEzxisdopnK8ILnnPPVUnPrzrCxLNWY8TR7kMioBuU/WT5ams9DcM5ipLH1oGoS2AS3LEsWkejsNIBvw7WMklR58TkMuQGo9WrsK0tk94GU6qCTU80bGHEZ9klW9/F57LJ3XMVhNAWlmaB/mSB44qS+TDixBPFVkvy2HypNYHJNU5vTUF7dRdavtu65w7fm1PLyndStsYMa3T++e1lVkTWVM878ANMtB6uozjZ/JeeCeC0PTc1itTcNo/MfM0VfeiAddzykj8nH+zipSXStWRl8YVbXaxjSaewbLQoaFhYVEBWmGgx23T1OrQPsgdRUbK8vf7TfjKlaBLE24/hhjs1o1gI76ViaxdmyLHM3W0LL8Emmf9R61PeuHG0KbgeZeRQJIlhsHUsDc+9AB2HNm7NSHuVTtGkN5cUb+PhgMMB6PG6nKapfrUXWsA86YzcNxfUzFfVZ170lFs7r71K7S/DNY6E53V5XZkSy1czXG7k5kikX4OrW09DzQSgSrZzwedyIKXN7qyPMc4/EYZVk23n2P2TQIbscYAnjPoC/O6THWrOoROAwYLJKj1R6SfWeqBqz+Dh/A86DyIHoguc+toJLEU0csOdq+pXHPbt/T7FrFeH2ZG/rSWX0qkdX/NyvNPQYD0mWOGA+lg2Ur3lTflWnUHQCkg2MZpXwNt6WSSXFRn+q1wdWQkZZTaaNM6NXN/dH7NBzoZcoyRlyJ5l6CAakX3suhqt7q/k1FFQ/ZNfzGa2ywL3FPjQKVVHaOSV8IzxWxUr+5fnXXmBuC3RF6jb6Y61ZkTQH8hraBYu8hhVBLjFgmUoLdD4pB+tSOuiXsux7jeryy6mT1gHefmuM6uW7O0LDnwdaiSmmWoqvdiGHuGaxisQxlUaUw6wAAxkChSiTMAKCb56UYyAPvqoaUERgH6Zr9XDe3wVPMNE7Y1659Wr1e6g0DfpPAKq2YNDFxViabewazwaweUGtVKSZiZlMM5pn2rHY1dGIDqG4NBd/MVIprvPwyVlPWjscYKmXZv8X98DaTsHvqO8d9mYXmHoOxeQ1U6cshVE5KfrtTlVFJPCBVXRpysofMqzazq8LKakKgp8qUNMLAg2/XMWP1OVO5DY1rcgiMN4xXiacbTXA/VqK5l2BsYpsEUwkEVOk5ZVE2m8ED6SB6eVnMJDwIPGhM3mIjHt5R5kvvAZ3yanAwc7M61AwOD695+I6vWw3ABw4DBkssMHSBdPqmtyEXXTCYfWJ2TM19PWZkkkIXIuaFRRTfeYOo0ksllid1VHIamcQqiqLjYlFVqse43pVo7hmM1UyeZSjLfmejqiF7e3lteMZqnjryBkHbse8s4djDz0yoVqXel5fhwd+NgTQ9vElNIsm8kn9LMeQsdFhgMH7o1fJL/Yu6sZVXlc+SXDCrx7CKYhYNLfWpQj6n361+r4wOrDE6M4xdzy+ABtPtGpXOdr9eJiyQhqJmocNCgrXMlHrFeQB4zyB1Nlo97DZQK6ovQ8NzIXTwn1h4LCmMvARD+25SiqWRNymE69Hv2rZ92iqIfHxWgA8cBgzGFEJ3AZBW4lRlPAOAcZya833qQq0/Owaki9DptYrrPMPCYxZ1gKoxwXUzkFcQz2V5UZZUCxyi5Zvu7xSRDh7QqrqQpbNzGOizpaYTWL2EPSO21lQyqEr0pKVJWuuHAndW3bZGbJ9LRNUyf/L9qeTWsNJqLEjgMGCw5KFEoCwiAjIEiGe6ZipbOpM3/uwD0ppI6Flsatrbb3UheCDe2vaySdX1wPeqjOBJUy6jffKYse/alWjuQT4D8HbdVXtoXYciP1y27PSY4iodGFY9Ki09q9J+e45fI5v9xPfG13LbXAer8WnuDe2P3S8z8Gp9YXPPYMCUVf9Catlx0JctRC4DdLMSjBQjWRmrz8vk4Hr0ODMcqzHGiNxvDycxKFdGA1qr0FOZ5p7RF201QH/uVeRoNALQ96C7KsJ+syWmEkfDOHZOmcPIw1vsXlAVphhI9yHi8JNdz2tQdF0z1ZpkzIi87xL3yUidwNYXfalWormXYJri3A5MOs2/WpGwvU4zH5TJpllSff4tZhA7NxqNMBwOm8HmZQHsWl20l7+zMcDYUNXk/v37m7p06QG+L+/e1OJlP9lKtGoJNstOH9/4xjfwq7/6q9iyZQs2bdqEM888Ezt37mzO79+/Hzt27MAxxxyDI444As985jM7a7Lu3LkT5513HjZu3IjjjjsOF110UeKNnpU8ydDgL9ooK1JZXtZbA792vUoTbkvbU4zDn7pkpfm0VF2yROF69b446sB/bMBwbj0HurVv3HemNXW0rrTTx7e//W087nGPw8knn4xPfepT+MpXvoLXvOY12LBhQ1Pm5S9/OT784Q/jAx/4AK699lrceuuteMYzntGcL4oC5513HkajET73uc/hve99L6644gpccsklq+1u45m2B8ITVquBqf6Y2TgzwmMMBcY64NMGycur52S/xm0S0onChokU/6hFq1anJ4XtuDGdMZ5d52VPeFbsLBTirKzoXRwCPvjBD+L8889vjj372c/GcDjEf//v/929Zvfu3XjAAx6A973vfXjWs54FAPjmN7+Jhz/84bjuuuvwmMc8Bh/96EfxtKc9DbfeemuzPv7ll1+Oiy++GHfccUeyQUMf7dmzB1u2bMHrX/96LC0tdawhvgc7pkCXGclWpembeu9Zflont+35mow8xmZ3iTK/ZzlaPbqzSJ/Lg53G3J5n9YYQsH//fvyn//SfsHv37nZFb4cOKMgvyxL/5//8H/zMz/wMzj33XBx33HE466yzEjV6/fXXYzwe45xzzmmOnXzyyTjxxBNx3XXXAah2+jjttNOSzRjOPfdc7NmzBzfddJPbdt9OH6pSFFgzyGX1qKSgvw+496lUez4aY1Trka1Frw1mCHWZWBlNQvSYi/uk7hk2eIx+lFQd4AAz2O233457770Xf/RHf4Rf/uVfxsc//nH82q/9Gp7xjGfg2muvBVDt1LGwsICjjjoquXbbtm1rstOHDqpmDKg6YQY04gfuCXx1I3jMY1KBjQcF/HwN902llycFrR9FUWA8HiPGams/y6O3WeDaZ37R9DlwWxxFWA2THXAJBgBPf/rT8fKXvxyPfOQj8cpXvhJPe9rTcPnllx/IpjrUt9MHM4v6ivStZeDL5Ux9KHN6jKSAn/GVbkxlpEyrbXiMwe1ze3yNTtBVic0BcXbRcN1qoPALMwsdUAY79thjMRgMcMoppyTHH/7whzdW5PHHH4/RaIS77747KXPbbbetyU4fDNxVzPNDVEniDQo/bPZPGak/zcNEgD+lTdV430ug0saIcRyrRT6WGjet2lepqS8O/9lLotkafXRAGWxhYQFnnnkmbr755uT4t771LTz4wQ8GAJx++ukYDoe45pprmvM333wzdu7cibPPPhtAtdPHV7/61WTLmauvvhqbN2/uMO9KxMygDGLn7VPfcD5u1E4gad9mXRjFyrBaYQbX6z3LUK9htcpMqGrYmMDqMRXL964vSZ/a4+MaLpt1+aYDvtPHRRddhN/4jd/A4x//ePziL/4irrrqKnz4wx/Gpz71KQDVJgvPf/7zceGFF2Lr1q3YvHkzXvziF+Pss8/GYx7zGADAk5/8ZJxyyil47nOfize+8Y3YtWsXXv3qV2PHjh1YXFxcbZcBdAPBKgVUctl3z6LjN9qu5YV2eVC0Plad3CdevlIZV9UVYzJrX+OUXFaPGbN46p6/q+WtoapZ6IDv9PFrv/ZruPzyy3HppZfiJS95CR72sIfhf//v/43HPe5xzTVvfvObkWXVDh/Ly8s499xz8a53vas5n+c5PvKRj+BFL3oRzj77bGzatAnPe97z8LrXvW613U0khvqY7DwwPeVY33C1sJRReRCUOVgScP+UObguDgupm8HOW7oO918lJddnPjCOGni4is+txsHaPI+42it+TMj8YH/wB3+ApaWlDq7RYLCqOLXaFLcZaciFU445SMwqzCMFz2p09PnfrCy3p4aGXpPneRMtsPJs3fILqfMDrO7l5eWD7we7vxJjHH2YQDcJT4G3SgAbAF0AjlWkShkgBd+Kn7wgNfdX3S0qpawv2nedKsfYUC1HIMWYOrOK+zkrzX2wWy0kI09SMPjVQedBtbefVYYCbaAbNGYG4GuV4bV/dq2uJM11KjbSl0H7pmrca1st2B+F5p7BgFStsSpT/KGD7j10/s0SyEtjYWmppr61wZYfSxoe9D7m0XvT/mmfPSDv4UdlQsZ5fc+jj+ZeRfJgMLbSMsoIXI7dDZ4FpSqLfUveQPTlmTFNU0d998CfypCeMcP32vQXXelu9XmG0Eo09wxmxGrPQid8Dkj9WkbMVPYme9kKWoYBOks5vc4Gq8/8V9Wm0kslDqt56zszO1+rGKyZRBICov05WNIMoVlo7hnMwx724HlA1TnpDYqd13iiShllGmWIvswONRDselNNqr5VLXNfFU/2MQpLr6IoqqxLZmJyDjNOXLOEwx9XUsaxB6oPzxiPy+laXsoARh6j6TGun90B1g4bFGVZNhNq1R+napbb73Op2DF2azATcq4c99/7mzX5c+5Bvg2cpw6A1JnK0mUawNbvfYBZSSWp9cfCWH3rcKk1aP3nY2yUqBpW65MlM+M8jgawmyOgi+NmxWBzz2CMmRhbWR48P+TBYNBICyBlTlUn+rA5FceOK7P0WX/erKA+i4/bMtIXg8sz0ygjMtm1MUaUxNB5niOrpT1L/HUVWROL+cFg0DgSFXADrbOSB9dzSmo2hF0/Ho+bXCyWiIAPzrkOD0t5EsNUu2IqnijMTOAZCHYtO1W9TeMBIJbpDCaVpCvR3DMYkA6QvnmqAtWyY0vMyqsbA2hXOfRysCzdWp2iyuD8MngpP+zDY3yYZVkike1vMpkk8wu0Pn4GicQESX55lmWsFmAo1xmsIpUMrObsvAJdBvsAkmxQxTL83c6pdcmTW/vwGlt91ra337dKIV76Uh3DHL/UF0LDT/ysbOP7EEKzRneMsVq/oz4f1lVkRSol7Hufi8FUKTOCSYk+JvGY2HMNaGxPJZ0yrdZt5T31yy8E90+npNm1vK4s94mlNtBKKq+vs9BhA/K9wQN8v5ddx9ewS4HDJorD2N3Aalmli2cQNBKkLqsAXfGUldXsD/tUtc7hKDvO1zSLy9G5jPEiutJ6JZp7CaYDpxKAH7j99rbu02wGtkyZmcx3BaR4zbPw7HpVe95vAB0cZWEpvU9PJdr1nnWqvxOcWF2IErVqDF3n8zSaewYz8At01aU9RG/3Cu/hsxRRo4EtNlVVml7MIN4m0zJWsnPMfNxvlpJatzK7HtOXBkgnGvMf94mvn5W5gMNARU4mk2YQWc0BrTeckwRVlXqSQEG3kalClRQcKfCkkTKtWpMsCfkevOus30YcflKJqi4KluyswtVZ62HXPpp7BvPSaPgBGeNpuAjoqlfFNCzFPCPCztngDIfDxOoz6nPQqqVpx5SRVLXqvao/zEjX/rf7ZLKXryiKZvPU1WCwuWcwL0mPid9a9RexytNgL4NdVlNWjtvlCSF97gJrx8A4n/eIJaG6GlRSKdPyOZWUWZY1fjBtz3tZV6K5ZzB9uz3VY+cVm9j1OiDTcAhLIlU11g7jGyvHC5B4Vq4xLd8Ll1crktuycsxEWja5H3pmhvdYRa8Gg809yFdmsT2KzNfFnnAvHsjmPatTIwX1zDR2vUkmb2BY3Srj9qlda8tIU434Wq63kVAhzSDRBVIQfMdxX9+m0dxLME6BsYfI2MNcCt68RrU2PSzHViSQqlyd68jXqcXpSSAry1LEs3ZVInI93j1oXJVxWOO6IQNA05dmnXQLHAYMpoBcsQgfA7pp1TpQqsKUMRhQ2zm7hrMm2IWhOEn7rvX2WZz2W/vvqXVtixmHGU5xJr9Us9BhwWDT8BK/xUbTpIp+tzmGhpH63Bpeeg0TM4FJXZaKmnKj9WufNHbK5xVrTnvp1CLWOlaiucdgikXse5P7RFJGMyk8v5j+AW2WKvuTvEFjdcTXGcBnFe0xqp7zMJE6RfvKKT60ugeypKcxLMct10E+kQ2ipj17kxaYYQDf888DCaCz7pYZDyxldONPNhSKosBoNGosNMWM1q6uJ+FJEDYwrAyrYnXO2rnxeNww+Wg0QhlTp7AyZV/7Hs09g/W9deyF17ee8YaGW9jysvoZ55i6NAlouWDj8bhpm6WmkW7Mzm0CaHK7NB7JUkgjCyqNrW4PGybGhPTTngn/9iSsR4cFBuM3mnGOOlf5Gv5UN4OGTviYFxS3Orxgt/aLpYtJNc83xsfM9aLpQNYvvj/1gXEbxohZlmFc12l1cb/XQT5RY3aHkAwa4IN5djPYMZZwyiAeKLbfPGA60Co5uH19IVg6eu2rSufrrDwz33g8bpZP1/bKsspitb6xc1Wx5Cw0twxmD9tUkw6eHdNB4XNWDw+W1sHSrM/NYHWbugS6IR4rz55ylTKmAi1PzMpZvdpn9o+pBWjrtyqFUM3uhtyr+tGWl5eT59xHc7t803e+8x089KEPPdTdmHu65ZZb8KAHPaj3/NxKsK1btwKodgzZsmXLIe7N/zvt2bMHJ5xwAm655Zap63EdLIox4p577sH27dunlptbBjOVsGXLlvvFgBwo4gWODzXN8uLOvZtinQ4trTPYOq0pzS2DLS4u4nd/93d/5FWp72/043o/c2tFrtP9g+ZWgq3T/YPWGWyd1pTWGWyd1pTWGWyd1pTWGWyd1pTmlsHe+c534iEPeQg2bNiAs846C1/84hcPdZc6dOmll+LMM8/EkUceieOOOw7nn39+Z6e6Jz7xiZ0s2t/+7d9OyuzcuRPnnXceNm7ciOOOOw4XXXTRzGuorjnFOaT3v//9cWFhIf7Zn/1ZvOmmm+ILXvCCeNRRR8XbbrvtUHctoXPPPTe+5z3viV/72tfijTfeGJ/61KfGE088Md57771NmSc84QnxBS94Qfznf/7n5m/37t3N+clkEk899dR4zjnnxL/927+Nf/3Xfx2PPfbY+KpXvepQ3FKH5pLBHv3oR8cdO3Y0v4uiiNu3b4+XXnrpIezVynT77bdHAPHaa69tjj3hCU+IL33pS3uv+eu//uuYZVnctWtXc+yyyy6LmzdvjsvLy2vZ3Zlo7lTkaDTC9ddfn2w6n2UZzjnnnGbT+fsr7d69G0CbCWJ05ZVX4thjj8Wpp56KV73qVdi7d29z7rrrrsNpp52W7HF+7rnnYs+ePbjpppsOTsen0NxlU/zgBz9AURTupvLf/OY3D1GvVqayLPGyl70Mj33sY3Hqqac2x3/zN38TD37wg7F9+3Z85StfwcUXX4ybb74Zf/EXfwEA2LVrl3uvdu5Q09wx2I8r7dixA1/72tfwN3/zN8nxF77whc330047DQ984APxpCc9Cd/+9rd/LBIq505FHnvsscjz3N1Uvm9D+UNNF1xwAT7ykY/gk5/85NTsUAA466yzAKDZ1vr4449379XOHWqaOwZbWFjA6aefnmw6X5YlrrnmmmbT+fsLxRhxwQUX4IMf/CA+8YlP4KSTTlrxmhtvvBEA8MAHPhAAcPbZZ+OrX/0qbr/99qbM1Vdfjc2bN+OUU05Zk36vig61lbEW9P73vz8uLi7GK664In7961+PL3zhC+NRRx2VWFr3B3rRi14Ut2zZEj/1qU8lboi9e/fGGGP8h3/4h/i6170ufvnLX47f/e5341/91V/Fn/zJn4yPf/zjmzrMTfHkJz853njjjfGqq66KD3jAA9bdFGtNb3/72+OJJ54YFxYW4qMf/ej4+c9//lB3qUOoFm7u/L3nPe+JMca4c+fO+PjHPz5u3bo1Li4uxp/6qZ+KF110UeIHizHGf/zHf4xPecpT4tLSUjz22GPjK17xijgejw/BHXVpPR9sndaU5g6DrdP9i9YZbJ3WlNYZbJ3WlNYZbJ3WlNYZbJ3WlNYZbJ3WlNYZbJ3WlNYZbJ3WlNYZbJ3WlNYZbJ3WlNYZbJ3WlP5/6EaxyIv4KdcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "original_img = cv2.imread('/content/1.jpg', cv2.IMREAD_COLOR)\n",
        "run(original_img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jshe56G3VAnK"
      },
      "source": [
        "# image preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoopdz97VFDG"
      },
      "outputs": [],
      "source": [
        "def preprocessing(img):\n",
        "  img_size = 224\n",
        "  image_array = cv2.imread(img, cv2.IMREAD_COLOR)\n",
        "  # get the width and height of image\n",
        "  width, height = Image.open(img).size\n",
        "  # to check if all image could resize\n",
        "  try:\n",
        "    resized_img = cv2.resize(image_array, (img_size, img_size))\n",
        "  except:\n",
        "    print('check size!')\n",
        "  x = np.array(resized_img) / 255\n",
        "  x = x.reshape(-1, img_size, img_size, 3)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if2M6DvxVTqL"
      },
      "source": [
        "## predict each image separately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlViLg1_avBx",
        "outputId": "9c025cd1-d7ba-4e38-b85f-88e4f7b5e2a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word_0.jpg\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "0.31179097\n",
            "panadol\n",
            "Word_1.jpg\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "0.3117764\n",
            "cataflam\n",
            "Word_2.jpg\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "0.31168386\n",
            "brufen\n",
            "Word_3.jpg\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "0.31179014\n",
            "Diclac\n",
            "Word_4.jpg\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "0.3116029\n",
            "panadol\n",
            "Word_5.jpg\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "0.31175864\n",
            "brufen\n",
            "Word_6.jpg\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "0.3117741\n",
            "panadol\n",
            "Word_7.jpg\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "0.3117908\n",
            "panadol\n",
            "Word_8.jpg\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "0.31052\n",
            "Actos\n",
            "Word_9.jpg\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "0.31179097\n",
            "Diclac\n"
          ]
        }
      ],
      "source": [
        "for images in natsorted(os.listdir('/content/Words')):\n",
        "  print(images)\n",
        "  image = preprocessing(f'/content/Words/{images}')\n",
        "\n",
        "  cv2.imwrite(f\"/content/Word_{i}.jpg\", image)\n",
        "  i+=1\n",
        "\n",
        "  pred=model.predict(image)\n",
        "  softmax = tf.nn.softmax(pred)\n",
        "  predictions = np.argmax(pred, axis=-1)\n",
        "  prediction_num = predictions[0]\n",
        "\n",
        "  print(softmax.numpy()[0][prediction_num])\n",
        "  print(classes[predictions[0]])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rqVFOvN7kVhj"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('python_10')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "b35187bd8e81c46a491b0701dacbc6455fb6bb49fda2ea4057c13cf77d84decb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}